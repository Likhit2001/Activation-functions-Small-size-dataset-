{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82494a0c-f7d4-4359-b5f9-3ed922e28f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.13.0\n",
      "GPU is  Available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"tensorflow version : {tf.__version__}\")\n",
    "# print(f\"keras version : {tensorflow.keras.__version__}\")\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is \" , \"Available\" if gpu else \"NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf95bbb1-3ae6-43ec-a7f0-6605be48ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import precision_score\n",
    "from tensorflow.keras import regularizers\n",
    "import shutil\n",
    "import glob\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Dense\n",
    "from keras.layers import Conv2D , GlobalAveragePooling2D , MaxPooling2D,Dropout , Flatten , Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.framework.func_graph import flatten\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import  InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import  preprocess_input\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b75f63-fbf8-4a65-862f-a927dd2ee984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Dress', 6000), ('Sneaker', 6000), ('Coat', 6000), ('Sandal', 6000), ('Angle boot', 6000), ('T-shirt', 6000), ('Bag', 6000), ('Shirt', 6000), ('Pullover', 6000), ('Trouser', 6000)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"data\"\n",
    "number_of_images = {}\n",
    "\n",
    "for dir in os.listdir(root_dir):\n",
    "    # Ignore .DS_Store files\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Check if the item is a directory before listing its contents\n",
    "    if os.path.isdir(os.path.join(root_dir, dir)):\n",
    "        number_of_images[dir] = len(os.listdir(os.path.join(root_dir, dir)))\n",
    "\n",
    "print(number_of_images.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917d50d1-0d00-470f-892b-0a2e323f8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldercreation (path , split) :\n",
    "    if not os.path.exists('./'+path):\n",
    "      os.mkdir('./'+path)\n",
    "\n",
    "      for dir in os.listdir(root_dir):\n",
    "        if dir == '.DS_Store':\n",
    "           continue\n",
    "            \n",
    "        os.makedirs('./'+path+\"/\"+dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)) , size = (math.floor(split * number_of_images[dir])-5) , replace=False):\n",
    "          Original = os.path.join(root_dir,dir,img)\n",
    "          Destination =os.path.join('./'+path , dir)\n",
    "          shutil.copy(Original,Destination)\n",
    "          # os.remove(Original)\n",
    "\n",
    "    else:\n",
    "      print(\"The folder exsist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d030332f-42c5-45fe-a9df-0b2a9b5017d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder exsist\n",
      "The folder exsist\n",
      "The folder exsist\n"
     ]
    }
   ],
   "source": [
    "foldercreation(\"train_data\",0.7)\n",
    "foldercreation(\"validation_data\",0.15)\n",
    "foldercreation(\"test_data\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1199e693-d2a0-4659-8991-706065051243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = ImageDataGenerator (\n",
    "                                     \n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      preprocessing_function= preprocess_input,\n",
    "                                )\n",
    "\n",
    "image=image_data.flow_from_directory(directory=\"train_data\" ,\n",
    "                                       target_size=(28,28),\n",
    "                                       batch_size=32,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964c9fed-0872-4410-9a39-496bbb9903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2 (path):\n",
    "  image_data = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "  image = image_data.flow_from_directory(directory = path,\n",
    "                                         target_size=(28,28),\n",
    "                                         batch_size = 32,\n",
    "                                         shuffle=True,\n",
    "                                         class_mode = \"categorical\")\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd18e7b0-ba7d-4a5f-980a-7dc3073d0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_test =\"test_data\"\n",
    "test_data = preprocessing2(path_test)\n",
    "X_test , Y_test = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304013d9-6d94-42dc-8e5f-6e07aa03aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_validate=\"validation_data\"\n",
    "validate_data = preprocessing2(path_validate)\n",
    "validate_data_1 , validate_labels = validate_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9579cd-cd00-4c61-bf70-6e9c4fc0a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = tf.nn.softplus\n",
    "def model_layer_1 (inputs,filters):\n",
    "\n",
    "\n",
    "  convo_2x2 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='softplus')(inputs)\n",
    "  convo_3x3 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='softplus')(inputs)\n",
    "  pool_conv = Conv2D(filters=filters[2], kernel_size=(3,3), padding='same', activation='softplus')(inputs)\n",
    "\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([convo_2x2, convo_3x3, pool_conv])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_2 (inputs,filters):\n",
    "\n",
    "\n",
    "\n",
    "  convo_3x3 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='softplus')(inputs)\n",
    "  pool_3x3 =MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(convo_3x3)\n",
    "\n",
    "  convo_5x5 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='softplus')(inputs)\n",
    "  pool_5x5 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(convo_5x5)\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([pool_3x3, pool_5x5])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_3 (inputs,filters):\n",
    "    \n",
    "  convo_1x1 = Conv2D(filters=filters[0], kernel_size=(3,3), padding='same', activation='softplus')(inputs)\n",
    "  pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "  outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "# def model_layer_5 (inputs,filters):\n",
    "    \n",
    "#   convo_1x1 = Conv2D(filters=filters[0], kernel_size=(5,5), padding='same', activation='relu')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "# def model_layer_6 (inputs):\n",
    "    \n",
    "#   pool_3x3 = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, pool_3x3])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fb6b60-b00f-4849-a8f0-cd2f02b411fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:25:59.770793: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-12-18 01:25:59.770831: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-18 01:25:59.770841: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-18 01:25:59.770906: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-18 01:25:59.770944: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "# define input tensor\n",
    "\n",
    "input_tensor = Input(shape=(28, 28, 3))\n",
    "\n",
    "\n",
    "original_model = model_layer_3(input_tensor,[128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "\n",
    "\n",
    "original_model = model_layer_1(original_model,[32,64,128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2),padding='same')(original_model)\n",
    "original_model = model_layer_2(original_model,[128,64])\n",
    "\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "original_model = model_layer_3(original_model,[128])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc7fa87-ee6b-492e-8b39-c938722e9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_model = Flatten()(original_model)\n",
    "original_model = Dense(512, activation='softplus' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dense(256, activation='softplus' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dropout(0.5)(original_model)\n",
    "\n",
    "output_tensor = Dense(10, activation='softmax' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "\n",
    "original_model = Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040bd7f7-895c-4e21-9194-c500ec6c59a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 28, 28, 3)            0         ['input_1[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 28, 28, 128)          3584      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 28, 28, 131)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 131)          0         ['concatenate[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)           16800     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)           75520     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 128)          151040    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 14, 14, 224)          0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_2[0][0]',            \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 224)            0         ['concatenate_1[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)            114816    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)             129088    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)            0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 7, 7, 192)            0         ['max_pooling2d_3[0][0]',     \n",
      " )                                                                   'max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 192)            0         ['concatenate_2[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 4, 4, 192)            0         ['max_pooling2d_5[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)            221312    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 4, 4, 320)            0         ['max_pooling2d_6[0][0]',     \n",
      " )                                                                   'conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 5120)                 0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  2621952   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 10)                   2570      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3468010 (13.23 MB)\n",
      "Trainable params: 3468010 (13.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909495f2-933b-4cfa-826b-bbb1890983f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "original_model.compile(optimizer= opt ,\n",
    "              loss= keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy' , 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab155de-6383-4f99-adce-e2d575457f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor=\"accuracy\",\n",
    "                          min_delta=0.01 , patience=3,\n",
    "                          verbose=1,\n",
    "                          mode=\"auto\")\n",
    "modelcheckpoint = ModelCheckpoint(monitor=\"accuracy\",\n",
    "                                  filepath = \"./softplus.h5\",\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  mode =\"auto\"\n",
    "                                  )\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-3)\n",
    "\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        predictions = self.model.predict(x_val)\n",
    "        \n",
    "        # Calculate top-5 accuracy\n",
    "        top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "        true_labels = np.argmax(y_val, axis=1)\n",
    "        top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Top-5 Accuracy: {top_5_accuracy:.4f} - Precision: {precision:.4f}')\n",
    "\n",
    "\n",
    "metrics_callback = MetricsCallback(validation_data=(validate_data_1, validate_labels))\n",
    "\n",
    "callbs = [earlystop,modelcheckpoint,lr_scheduler,metrics_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fdd759-3059-4565-912b-aa46961a283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:26:01.908759: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 1.4980 - accuracy: 0.5811 - auc: 0.9311"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:29:51.137833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.58110, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2023-12-18 01:29:56.401120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 434ms/step\n",
      "Epoch 1 - Top-5 Accuracy: 1.0000 - Precision: 0.8313\n",
      "1311/1311 [==============================] - 235s 175ms/step - loss: 1.4980 - accuracy: 0.5811 - auc: 0.9311 - val_loss: 0.6708 - val_accuracy: 0.8125 - val_auc: 0.9849 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.7468 - accuracy: 0.7524 - auc: 0.9755\n",
      "Epoch 2: accuracy improved from 0.58110 to 0.75240, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n",
      "Epoch 2 - Top-5 Accuracy: 1.0000 - Precision: 0.7750\n",
      "1311/1311 [==============================] - 224s 171ms/step - loss: 0.7468 - accuracy: 0.7524 - auc: 0.9755 - val_loss: 0.5355 - val_accuracy: 0.8438 - val_auc: 0.9895 - lr: 0.0010\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.7794 - auc: 0.9797\n",
      "Epoch 3: accuracy improved from 0.75240 to 0.77936, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n",
      "Epoch 3 - Top-5 Accuracy: 1.0000 - Precision: 0.9141\n",
      "1311/1311 [==============================] - 233s 177ms/step - loss: 0.6564 - accuracy: 0.7794 - auc: 0.9797 - val_loss: 0.4178 - val_accuracy: 0.8750 - val_auc: 0.9945 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.7997 - auc: 0.9826\n",
      "Epoch 4: accuracy improved from 0.77936 to 0.79971, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "Epoch 4 - Top-5 Accuracy: 1.0000 - Precision: 0.9182\n",
      "1311/1311 [==============================] - 188s 143ms/step - loss: 0.5964 - accuracy: 0.7997 - auc: 0.9826 - val_loss: 0.5057 - val_accuracy: 0.8438 - val_auc: 0.9901 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.8120 - auc: 0.9843\n",
      "Epoch 5: accuracy improved from 0.79971 to 0.81201, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 152ms/step\n",
      "Epoch 5 - Top-5 Accuracy: 0.9688 - Precision: 0.9375\n",
      "1311/1311 [==============================] - 168s 128ms/step - loss: 0.5621 - accuracy: 0.8120 - auc: 0.9843 - val_loss: 0.3885 - val_accuracy: 0.9062 - val_auc: 0.9941 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.8210 - auc: 0.9853\n",
      "Epoch 6: accuracy improved from 0.81201 to 0.82095, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "Epoch 6 - Top-5 Accuracy: 1.0000 - Precision: 0.9420\n",
      "1311/1311 [==============================] - 158s 120ms/step - loss: 0.5410 - accuracy: 0.8210 - auc: 0.9853 - val_loss: 0.3219 - val_accuracy: 0.9062 - val_auc: 0.9962 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.8271 - auc: 0.9864\n",
      "Epoch 7: accuracy improved from 0.82095 to 0.82713, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "Epoch 7 - Top-5 Accuracy: 1.0000 - Precision: 0.9115\n",
      "1311/1311 [==============================] - 149s 114ms/step - loss: 0.5203 - accuracy: 0.8271 - auc: 0.9864 - val_loss: 0.3009 - val_accuracy: 0.8750 - val_auc: 0.9969 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.8354 - auc: 0.9872\n",
      "Epoch 8: accuracy improved from 0.82713 to 0.83545, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 8 - Top-5 Accuracy: 0.9688 - Precision: 0.9479\n",
      "1311/1311 [==============================] - 130s 99ms/step - loss: 0.4977 - accuracy: 0.8354 - auc: 0.9872 - val_loss: 0.3946 - val_accuracy: 0.9062 - val_auc: 0.9932 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.8386 - auc: 0.9880\n",
      "Epoch 9: accuracy improved from 0.83545 to 0.83857, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Epoch 9 - Top-5 Accuracy: 0.9688 - Precision: 0.9115\n",
      "1311/1311 [==============================] - 81s 62ms/step - loss: 0.4837 - accuracy: 0.8386 - auc: 0.9880 - val_loss: 0.4302 - val_accuracy: 0.8750 - val_auc: 0.9911 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.8446 - auc: 0.9886\n",
      "Epoch 10: accuracy improved from 0.83857 to 0.84455, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 10 - Top-5 Accuracy: 1.0000 - Precision: 0.9229\n",
      "1311/1311 [==============================] - 78s 59ms/step - loss: 0.4664 - accuracy: 0.8446 - auc: 0.9886 - val_loss: 0.3331 - val_accuracy: 0.9062 - val_auc: 0.9956 - lr: 0.0010\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.8470 - auc: 0.9890\n",
      "Epoch 11: accuracy improved from 0.84455 to 0.84703, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 11 - Top-5 Accuracy: 1.0000 - Precision: 0.9313\n",
      "1311/1311 [==============================] - 80s 61ms/step - loss: 0.4598 - accuracy: 0.8470 - auc: 0.9890 - val_loss: 0.4958 - val_accuracy: 0.8750 - val_auc: 0.9899 - lr: 0.0010\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8516 - auc: 0.9892\n",
      "Epoch 12: accuracy improved from 0.84703 to 0.85159, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 12 - Top-5 Accuracy: 1.0000 - Precision: 0.9557\n",
      "1311/1311 [==============================] - 79s 61ms/step - loss: 0.4517 - accuracy: 0.8516 - auc: 0.9892 - val_loss: 0.3059 - val_accuracy: 0.9375 - val_auc: 0.9963 - lr: 0.0010\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.8540 - auc: 0.9899\n",
      "Epoch 13: accuracy improved from 0.85159 to 0.85404, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Epoch 13 - Top-5 Accuracy: 1.0000 - Precision: 0.9420\n",
      "1311/1311 [==============================] - 79s 60ms/step - loss: 0.4422 - accuracy: 0.8540 - auc: 0.9899 - val_loss: 0.2729 - val_accuracy: 0.9062 - val_auc: 0.9973 - lr: 0.0010\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310/1311 [============================>.] - ETA: 0s - loss: 0.4334 - accuracy: 0.8563 - auc: 0.9901\n",
      "Epoch 14: accuracy improved from 0.85404 to 0.85623, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Epoch 14 - Top-5 Accuracy: 0.9688 - Precision: 0.9479\n",
      "1311/1311 [==============================] - 68s 52ms/step - loss: 0.4335 - accuracy: 0.8562 - auc: 0.9901 - val_loss: 0.4055 - val_accuracy: 0.9062 - val_auc: 0.9795 - lr: 0.0010\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4308 - accuracy: 0.8556 - auc: 0.9902\n",
      "Epoch 15: accuracy did not improve from 0.85623\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Epoch 15 - Top-5 Accuracy: 1.0000 - Precision: 0.9313\n",
      "1311/1311 [==============================] - 62s 47ms/step - loss: 0.4308 - accuracy: 0.8556 - auc: 0.9902 - val_loss: 0.4804 - val_accuracy: 0.8750 - val_auc: 0.9893 - lr: 0.0010\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "final = original_model.fit(\n",
    "    image,\n",
    "    steps_per_epoch=len(image),\n",
    "    epochs=30,\n",
    "    validation_data=(validate_data_1, validate_labels),\n",
    "    validation_steps=len(validate_data_1),\n",
    "    verbose=1,\n",
    "    callbacks=callbs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267c3af-9966-4a29-8117-8e65505ffa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angle boot': 0,\n",
       " 'Bag': 1,\n",
       " 'Coat': 2,\n",
       " 'Dress': 3,\n",
       " 'Pullover': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'T-shirt': 8,\n",
       " 'Trouser': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b35d69a-77d7-4c8c-af93-8f3766c98097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Calculate top-5 accuracy\n",
    "    top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "    top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "\n",
    "    return top_5_accuracy, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c36fcf-e48f-46da-9b7f-4347dbbb947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 281ms/step - loss: 0.7519 - accuracy: 0.6875 - auc: 0.9633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:59:33.901110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7519018054008484\n",
      "Test accuracy: 0.6875\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      " Top-5 Accuracy: 1.0000\n",
      "Precision: 0.8187\n"
     ]
    }
   ],
   "source": [
    "prediction = original_model.evaluate(X_test , Y_test,verbose=1)\n",
    "print('Test loss:', prediction[0])\n",
    "print('Test accuracy:', prediction[1])\n",
    "\n",
    "predictions = original_model.predict(X_test)\n",
    "top_5_accuracy, precision = calculate_metrics(np.argmax(Y_test, axis=1), predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f' Top-5 Accuracy: {top_5_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4aef46e-dae6-47cf-93e5-33ad3ce2885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = final.history\n",
    "h.keys()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.title(\"Loss vs Acc\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
