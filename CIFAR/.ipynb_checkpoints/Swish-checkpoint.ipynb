{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82494a0c-f7d4-4359-b5f9-3ed922e28f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.13.0\n",
      "GPU is  Available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"tensorflow version : {tf.__version__}\")\n",
    "# print(f\"keras version : {tensorflow.keras.__version__}\")\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is \" , \"Available\" if gpu else \"NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf95bbb1-3ae6-43ec-a7f0-6605be48ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import precision_score\n",
    "from tensorflow.keras import regularizers\n",
    "import shutil\n",
    "import glob\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Dense\n",
    "from keras.layers import Conv2D , GlobalAveragePooling2D , MaxPooling2D,Dropout , Flatten , Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.framework.func_graph import flatten\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import  InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import  preprocess_input\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b75f63-fbf8-4a65-862f-a927dd2ee984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Dress', 6000), ('Sneaker', 6000), ('Coat', 6000), ('Sandal', 6000), ('Angle boot', 6000), ('T-shirt', 6000), ('Bag', 6000), ('Shirt', 6000), ('Pullover', 6000), ('Trouser', 6000)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"data\"\n",
    "number_of_images = {}\n",
    "\n",
    "for dir in os.listdir(root_dir):\n",
    "    # Ignore .DS_Store files\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Check if the item is a directory before listing its contents\n",
    "    if os.path.isdir(os.path.join(root_dir, dir)):\n",
    "        number_of_images[dir] = len(os.listdir(os.path.join(root_dir, dir)))\n",
    "\n",
    "print(number_of_images.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917d50d1-0d00-470f-892b-0a2e323f8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldercreation (path , split) :\n",
    "    if not os.path.exists('./'+path):\n",
    "      os.mkdir('./'+path)\n",
    "\n",
    "      for dir in os.listdir(root_dir):\n",
    "        if dir == '.DS_Store':\n",
    "           continue\n",
    "            \n",
    "        os.makedirs('./'+path+\"/\"+dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)) , size = (math.floor(split * number_of_images[dir])-5) , replace=False):\n",
    "          Original = os.path.join(root_dir,dir,img)\n",
    "          Destination =os.path.join('./'+path , dir)\n",
    "          shutil.copy(Original,Destination)\n",
    "          # os.remove(Original)\n",
    "\n",
    "    else:\n",
    "      print(\"The folder exsist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d030332f-42c5-45fe-a9df-0b2a9b5017d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder exsist\n",
      "The folder exsist\n",
      "The folder exsist\n"
     ]
    }
   ],
   "source": [
    "foldercreation(\"train_data\",0.7)\n",
    "foldercreation(\"validation_data\",0.15)\n",
    "foldercreation(\"test_data\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1199e693-d2a0-4659-8991-706065051243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = ImageDataGenerator (\n",
    "                                     \n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      preprocessing_function= preprocess_input,\n",
    "                                )\n",
    "\n",
    "image=image_data.flow_from_directory(directory=\"train_data\" ,\n",
    "                                       target_size=(28,28),\n",
    "                                       batch_size=32,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964c9fed-0872-4410-9a39-496bbb9903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2 (path):\n",
    "  image_data = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "  image = image_data.flow_from_directory(directory = path,\n",
    "                                         target_size=(28,28),\n",
    "                                         batch_size = 32,\n",
    "                                         shuffle=True,\n",
    "                                         class_mode = \"categorical\")\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd18e7b0-ba7d-4a5f-980a-7dc3073d0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_test =\"test_data\"\n",
    "test_data = preprocessing2(path_test)\n",
    "X_test , Y_test = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304013d9-6d94-42dc-8e5f-6e07aa03aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_validate=\"validation_data\"\n",
    "validate_data = preprocessing2(path_validate)\n",
    "validate_data_1 , validate_labels = validate_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9579cd-cd00-4c61-bf70-6e9c4fc0a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def swish(x):\n",
    "    return x * tf.nn.sigmoid(x)\n",
    "\n",
    "def model_layer_1 (inputs,filters):\n",
    "\n",
    "\n",
    "  convo_2x2 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='swish')(inputs)\n",
    "  convo_3x3 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='swish')(inputs)\n",
    "  pool_conv = Conv2D(filters=filters[2], kernel_size=(3,3), padding='same', activation='swish')(inputs)\n",
    "\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([convo_2x2, convo_3x3, pool_conv])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_2 (inputs,filters):\n",
    "\n",
    "\n",
    "\n",
    "  convo_3x3 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='swish')(inputs)\n",
    "  pool_3x3 =MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(convo_3x3)\n",
    "\n",
    "  convo_5x5 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='swish')(inputs)\n",
    "  pool_5x5 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(convo_5x5)\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([pool_3x3, pool_5x5])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_3 (inputs,filters):\n",
    "    \n",
    "  convo_1x1 = Conv2D(filters=filters[0], kernel_size=(3,3), padding='same', activation='swish')(inputs)\n",
    "  pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "  outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "# def model_layer_5 (inputs,filters):\n",
    "    \n",
    "#   convo_1x1 = Conv2D(filters=filters[0], kernel_size=(5,5), padding='same', activation='relu')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "# def model_layer_6 (inputs):\n",
    "    \n",
    "#   pool_3x3 = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, pool_3x3])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fb6b60-b00f-4849-a8f0-cd2f02b411fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:24:51.075577: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-12-18 01:24:51.075614: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-18 01:24:51.075654: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-18 01:24:51.075720: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-18 01:24:51.075765: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "# define input tensor\n",
    "\n",
    "input_tensor = Input(shape=(28, 28, 3))\n",
    "\n",
    "\n",
    "\n",
    "original_model = model_layer_3(input_tensor,[128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "\n",
    "\n",
    "original_model = model_layer_1(original_model,[32,64,128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2),padding='same')(original_model)\n",
    "original_model = model_layer_2(original_model,[128,64])\n",
    "\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "original_model = model_layer_3(original_model,[128])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc7fa87-ee6b-492e-8b39-c938722e9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_model = Flatten()(original_model)\n",
    "\n",
    "original_model = Dense(512, activation='swish' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dense(256, activation='swish' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dropout(0.5)(original_model)\n",
    "\n",
    "output_tensor = Dense(10, activation='softmax' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "\n",
    "original_model = Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040bd7f7-895c-4e21-9194-c500ec6c59a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 28, 28, 3)            0         ['input_1[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 28, 28, 128)          3584      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 28, 28, 131)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 131)          0         ['concatenate[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)           16800     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)           75520     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 128)          151040    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 14, 14, 224)          0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_2[0][0]',            \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 224)            0         ['concatenate_1[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)            114816    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)             129088    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)            0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 7, 7, 192)            0         ['max_pooling2d_3[0][0]',     \n",
      " )                                                                   'max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 192)            0         ['concatenate_2[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 4, 4, 192)            0         ['max_pooling2d_5[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)            221312    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 4, 4, 320)            0         ['max_pooling2d_6[0][0]',     \n",
      " )                                                                   'conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 5120)                 0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  2621952   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 10)                   2570      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3468010 (13.23 MB)\n",
      "Trainable params: 3468010 (13.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909495f2-933b-4cfa-826b-bbb1890983f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "original_model.compile(optimizer= opt ,\n",
    "              loss= keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy' , 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab155de-6383-4f99-adce-e2d575457f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor=\"accuracy\",\n",
    "                          min_delta=0.01 , patience=3,\n",
    "                          verbose=1,\n",
    "                          mode=\"auto\")\n",
    "modelcheckpoint = ModelCheckpoint(monitor=\"accuracy\",\n",
    "                                  filepath = \"./swish.h5\",\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  mode =\"auto\"\n",
    "                                  )\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-3)\n",
    "\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        predictions = self.model.predict(x_val)\n",
    "        \n",
    "        # Calculate top-5 accuracy\n",
    "        top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "        true_labels = np.argmax(y_val, axis=1)\n",
    "        top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Top-5 Accuracy: {top_5_accuracy:.4f} - Precision: {precision:.4f}')\n",
    "\n",
    "\n",
    "metrics_callback = MetricsCallback(validation_data=(validate_data_1, validate_labels))\n",
    "\n",
    "callbs = [earlystop,modelcheckpoint,lr_scheduler,metrics_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fdd759-3059-4565-912b-aa46961a283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:24:52.405187: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.9367 - accuracy: 0.7585 - auc: 0.9748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:26:22.163456: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.75852, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2023-12-18 01:26:27.784420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 811ms/step\n",
      "Epoch 1 - Top-5 Accuracy: 1.0000 - Precision: 0.8932\n",
      "1311/1311 [==============================] - 96s 71ms/step - loss: 0.9367 - accuracy: 0.7585 - auc: 0.9748 - val_loss: 0.6207 - val_accuracy: 0.8438 - val_auc: 0.9867 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.8365 - auc: 0.9874\n",
      "Epoch 2: accuracy improved from 0.75852 to 0.83647, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "Epoch 2 - Top-5 Accuracy: 1.0000 - Precision: 0.9271\n",
      "1311/1311 [==============================] - 176s 134ms/step - loss: 0.5556 - accuracy: 0.8365 - auc: 0.9874 - val_loss: 0.6469 - val_accuracy: 0.8438 - val_auc: 0.9871 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5060 - accuracy: 0.8578 - auc: 0.9894\n",
      "Epoch 3: accuracy improved from 0.83647 to 0.85781, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "Epoch 3 - Top-5 Accuracy: 1.0000 - Precision: 0.8958\n",
      "1311/1311 [==============================] - 160s 122ms/step - loss: 0.5060 - accuracy: 0.8578 - auc: 0.9894 - val_loss: 0.3370 - val_accuracy: 0.8438 - val_auc: 0.9967 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.8695 - auc: 0.9911\n",
      "Epoch 4: accuracy improved from 0.85781 to 0.86951, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 4 - Top-5 Accuracy: 1.0000 - Precision: 0.9583\n",
      "1311/1311 [==============================] - 165s 126ms/step - loss: 0.4598 - accuracy: 0.8695 - auc: 0.9911 - val_loss: 0.4442 - val_accuracy: 0.9062 - val_auc: 0.9929 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.8762 - auc: 0.9914\n",
      "Epoch 5: accuracy improved from 0.86951 to 0.87619, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 5 - Top-5 Accuracy: 1.0000 - Precision: 0.9583\n",
      "1311/1311 [==============================] - 170s 130ms/step - loss: 0.4492 - accuracy: 0.8762 - auc: 0.9914 - val_loss: 0.2989 - val_accuracy: 0.9062 - val_auc: 0.9980 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4327 - accuracy: 0.8801 - auc: 0.9921\n",
      "Epoch 6: accuracy improved from 0.87619 to 0.88012, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "Epoch 6 - Top-5 Accuracy: 1.0000 - Precision: 0.9792\n",
      "1311/1311 [==============================] - 144s 110ms/step - loss: 0.4327 - accuracy: 0.8801 - auc: 0.9921 - val_loss: 0.3360 - val_accuracy: 0.9375 - val_auc: 0.9972 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.8857 - auc: 0.9926\n",
      "Epoch 7: accuracy improved from 0.88012 to 0.88572, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "Epoch 7 - Top-5 Accuracy: 1.0000 - Precision: 0.9583\n",
      "1311/1311 [==============================] - 103s 79ms/step - loss: 0.4122 - accuracy: 0.8857 - auc: 0.9926 - val_loss: 0.3777 - val_accuracy: 0.9062 - val_auc: 0.9954 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8883 - auc: 0.9933\n",
      "Epoch 8: accuracy improved from 0.88572 to 0.88834, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 8 - Top-5 Accuracy: 1.0000 - Precision: 0.9583\n",
      "1311/1311 [==============================] - 138s 105ms/step - loss: 0.3998 - accuracy: 0.8883 - auc: 0.9933 - val_loss: 0.3615 - val_accuracy: 0.9062 - val_auc: 0.9967 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8924 - auc: 0.9933\n",
      "Epoch 9: accuracy improved from 0.88834 to 0.89240, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "Epoch 9 - Top-5 Accuracy: 1.0000 - Precision: 0.9635\n",
      "1311/1311 [==============================] - 104s 79ms/step - loss: 0.3942 - accuracy: 0.8924 - auc: 0.9933 - val_loss: 0.2972 - val_accuracy: 0.9375 - val_auc: 0.9974 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.8956 - auc: 0.9938\n",
      "Epoch 10: accuracy improved from 0.89240 to 0.89559, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 10 - Top-5 Accuracy: 1.0000 - Precision: 0.9792\n",
      "1311/1311 [==============================] - 104s 79ms/step - loss: 0.3797 - accuracy: 0.8956 - auc: 0.9938 - val_loss: 0.4028 - val_accuracy: 0.9375 - val_auc: 0.9804 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.8991 - auc: 0.9939\n",
      "Epoch 11: accuracy improved from 0.89559 to 0.89909, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "Epoch 11 - Top-5 Accuracy: 1.0000 - Precision: 0.9792\n",
      "1311/1311 [==============================] - 110s 84ms/step - loss: 0.3726 - accuracy: 0.8991 - auc: 0.9939 - val_loss: 0.3584 - val_accuracy: 0.9375 - val_auc: 0.9973 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.9008 - auc: 0.9942\n",
      "Epoch 12: accuracy improved from 0.89909 to 0.90076, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 12 - Top-5 Accuracy: 1.0000 - Precision: 0.9792\n",
      "1311/1311 [==============================] - 86s 66ms/step - loss: 0.3669 - accuracy: 0.9008 - auc: 0.9942 - val_loss: 0.2591 - val_accuracy: 0.9688 - val_auc: 0.9990 - lr: 0.0010\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "final = original_model.fit(\n",
    "    image,\n",
    "    steps_per_epoch=len(image),\n",
    "    epochs=30,\n",
    "    validation_data=(validate_data_1, validate_labels),\n",
    "    validation_steps=len(validate_data_1),\n",
    "    verbose=1,\n",
    "    callbacks=callbs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267c3af-9966-4a29-8117-8e65505ffa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angle boot': 0,\n",
       " 'Bag': 1,\n",
       " 'Coat': 2,\n",
       " 'Dress': 3,\n",
       " 'Pullover': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'T-shirt': 8,\n",
       " 'Trouser': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b35d69a-77d7-4c8c-af93-8f3766c98097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Calculate top-5 accuracy\n",
    "    top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "    top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "\n",
    "    return top_5_accuracy, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c36fcf-e48f-46da-9b7f-4347dbbb947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:50:50.986435: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 511ms/step - loss: 0.3331 - accuracy: 0.9062 - auc: 0.9973\n",
      "Test loss: 0.33312511444091797\n",
      "Test accuracy: 0.90625\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      " Top-5 Accuracy: 1.0000\n",
      "Precision: 0.9391\n"
     ]
    }
   ],
   "source": [
    "prediction = original_model.evaluate(X_test , Y_test,verbose=1)\n",
    "print('Test loss:', prediction[0])\n",
    "print('Test accuracy:', prediction[1])\n",
    "\n",
    "predictions = original_model.predict(X_test)\n",
    "top_5_accuracy, precision = calculate_metrics(np.argmax(Y_test, axis=1), predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f' Top-5 Accuracy: {top_5_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4aef46e-dae6-47cf-93e5-33ad3ce2885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = final.history\n",
    "h.keys()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.title(\"Loss vs Acc\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
