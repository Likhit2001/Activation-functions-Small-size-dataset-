{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82494a0c-f7d4-4359-b5f9-3ed922e28f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.13.0\n",
      "GPU is  Available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"tensorflow version : {tf.__version__}\")\n",
    "# print(f\"keras version : {tensorflow.keras.__version__}\")\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is \" , \"Available\" if gpu else \"NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf95bbb1-3ae6-43ec-a7f0-6605be48ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import precision_score\n",
    "from tensorflow.keras import regularizers\n",
    "import shutil\n",
    "import glob\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Dense\n",
    "from keras.layers import Conv2D , GlobalAveragePooling2D , MaxPooling2D,Dropout , Flatten , Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.framework.func_graph import flatten\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import  InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import  preprocess_input\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b75f63-fbf8-4a65-862f-a927dd2ee984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Dress', 6000), ('Sneaker', 6000), ('Coat', 6000), ('Sandal', 6000), ('Angle boot', 6000), ('T-shirt', 6000), ('Bag', 6000), ('Shirt', 6000), ('Pullover', 6000), ('Trouser', 6000)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"data\"\n",
    "number_of_images = {}\n",
    "\n",
    "for dir in os.listdir(root_dir):\n",
    "    # Ignore .DS_Store files\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Check if the item is a directory before listing its contents\n",
    "    if os.path.isdir(os.path.join(root_dir, dir)):\n",
    "        number_of_images[dir] = len(os.listdir(os.path.join(root_dir, dir)))\n",
    "\n",
    "print(number_of_images.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917d50d1-0d00-470f-892b-0a2e323f8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldercreation (path , split) :\n",
    "    if not os.path.exists('./'+path):\n",
    "      os.mkdir('./'+path)\n",
    "\n",
    "      for dir in os.listdir(root_dir):\n",
    "        if dir == '.DS_Store':\n",
    "           continue\n",
    "            \n",
    "        os.makedirs('./'+path+\"/\"+dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)) , size = (math.floor(split * number_of_images[dir])-5) , replace=False):\n",
    "          Original = os.path.join(root_dir,dir,img)\n",
    "          Destination =os.path.join('./'+path , dir)\n",
    "          shutil.copy(Original,Destination)\n",
    "          # os.remove(Original)\n",
    "\n",
    "    else:\n",
    "      print(\"The folder exsist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d030332f-42c5-45fe-a9df-0b2a9b5017d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder exsist\n",
      "The folder exsist\n",
      "The folder exsist\n"
     ]
    }
   ],
   "source": [
    "foldercreation(\"train_data\",0.7)\n",
    "foldercreation(\"validation_data\",0.15)\n",
    "foldercreation(\"test_data\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1199e693-d2a0-4659-8991-706065051243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = ImageDataGenerator (\n",
    "                                     \n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      preprocessing_function= preprocess_input,\n",
    "                                )\n",
    "\n",
    "image=image_data.flow_from_directory(directory=\"train_data\" ,\n",
    "                                       target_size=(28,28),\n",
    "                                       batch_size=32,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964c9fed-0872-4410-9a39-496bbb9903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2 (path):\n",
    "  image_data = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "  image = image_data.flow_from_directory(directory = path,\n",
    "                                         target_size=(28,28),\n",
    "                                         batch_size = 32,\n",
    "                                         shuffle=True,\n",
    "                                         class_mode = \"categorical\")\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd18e7b0-ba7d-4a5f-980a-7dc3073d0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_test =\"test_data\"\n",
    "test_data = preprocessing2(path_test)\n",
    "X_test , Y_test = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304013d9-6d94-42dc-8e5f-6e07aa03aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_validate=\"validation_data\"\n",
    "validate_data = preprocessing2(path_validate)\n",
    "validate_data_1 , validate_labels = validate_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9579cd-cd00-4c61-bf70-6e9c4fc0a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "\n",
    "def model_layer_1 (inputs,filters):\n",
    "\n",
    "\n",
    "  convo_2x2 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='mish')(inputs)\n",
    "  convo_3x3 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='mish')(inputs)\n",
    "  pool_conv = Conv2D(filters=filters[2], kernel_size=(3,3), padding='same', activation='mish')(inputs)\n",
    "\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([convo_2x2, convo_3x3, pool_conv])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_2 (inputs,filters):\n",
    "\n",
    "\n",
    "\n",
    "  convo_3x3 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='mish')(inputs)\n",
    "  pool_3x3 =MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(convo_3x3)\n",
    "\n",
    "  convo_5x5 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='mish')(inputs)\n",
    "  pool_5x5 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(convo_5x5)\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([pool_3x3, pool_5x5])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_3 (inputs,filters):\n",
    "    \n",
    "  convo_1x1 = Conv2D(filters=filters[0], kernel_size=(3,3), padding='same', activation='mish')(inputs)\n",
    "  pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "  outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "# def model_layer_5 (inputs,filters):\n",
    "    \n",
    "#   convo_1x1 = Conv2D(filters=filters[0], kernel_size=(5,5), padding='same', activation='relu')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "# def model_layer_6 (inputs):\n",
    "    \n",
    "#   pool_3x3 = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, pool_3x3])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fb6b60-b00f-4849-a8f0-cd2f02b411fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:26:14.940421: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-12-18 01:26:14.940464: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-18 01:26:14.940474: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-18 01:26:14.940540: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-18 01:26:14.940565: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "# define input tensor\n",
    "\n",
    "input_tensor = Input(shape=(28, 28, 3))\n",
    "\n",
    "\n",
    "original_model = model_layer_3(input_tensor,[128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "\n",
    "\n",
    "original_model = model_layer_1(original_model,[32,64,128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2),padding='same')(original_model)\n",
    "original_model = model_layer_2(original_model,[128,64])\n",
    "\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "original_model = model_layer_3(original_model,[128])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc7fa87-ee6b-492e-8b39-c938722e9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_model = Flatten()(original_model)\n",
    "original_model = Dense(512, activation='mish' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dense(256, activation='mish' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dropout(0.5)(original_model)\n",
    "\n",
    "output_tensor = Dense(10, activation='softmax' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "\n",
    "original_model = Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040bd7f7-895c-4e21-9194-c500ec6c59a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 28, 28, 3)            0         ['input_1[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 28, 28, 128)          3584      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 28, 28, 131)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 131)          0         ['concatenate[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)           16800     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)           75520     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 128)          151040    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 14, 14, 224)          0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_2[0][0]',            \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 224)            0         ['concatenate_1[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)            114816    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)             129088    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)            0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 7, 7, 192)            0         ['max_pooling2d_3[0][0]',     \n",
      " )                                                                   'max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 192)            0         ['concatenate_2[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 4, 4, 192)            0         ['max_pooling2d_5[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)            221312    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 4, 4, 320)            0         ['max_pooling2d_6[0][0]',     \n",
      " )                                                                   'conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 5120)                 0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  2621952   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 10)                   2570      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3468010 (13.23 MB)\n",
      "Trainable params: 3468010 (13.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909495f2-933b-4cfa-826b-bbb1890983f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "original_model.compile(optimizer= opt ,\n",
    "              loss= keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy' , 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab155de-6383-4f99-adce-e2d575457f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor=\"accuracy\",\n",
    "                          min_delta=0.01 , patience=3,\n",
    "                          verbose=1,\n",
    "                          mode=\"auto\")\n",
    "modelcheckpoint = ModelCheckpoint(monitor=\"accuracy\",\n",
    "                                  filepath = \"./mish.h5\",\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  mode =\"auto\"\n",
    "                                  )\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-3)\n",
    "\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        predictions = self.model.predict(x_val)\n",
    "        \n",
    "        # Calculate top-5 accuracy\n",
    "        top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "        true_labels = np.argmax(y_val, axis=1)\n",
    "        top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Top-5 Accuracy: {top_5_accuracy:.4f} - Precision: {precision:.4f}')\n",
    "\n",
    "\n",
    "metrics_callback = MetricsCallback(validation_data=(validate_data_1, validate_labels))\n",
    "\n",
    "callbs = [earlystop,modelcheckpoint,lr_scheduler,metrics_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fdd759-3059-4565-912b-aa46961a283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:26:17.676731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.9691 - accuracy: 0.7635 - auc: 0.9753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:30:37.451253: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.76350, saving model to ./mish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2023-12-18 01:30:43.294491: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 752ms/step\n",
      "Epoch 1 - Top-5 Accuracy: 1.0000 - Precision: 0.8375\n",
      "1311/1311 [==============================] - 267s 200ms/step - loss: 0.9691 - accuracy: 0.7635 - auc: 0.9753 - val_loss: 0.7483 - val_accuracy: 0.8125 - val_auc: 0.9776 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5815 - accuracy: 0.8356 - auc: 0.9867\n",
      "Epoch 2: accuracy improved from 0.76350 to 0.83557, saving model to ./mish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n",
      "Epoch 2 - Top-5 Accuracy: 1.0000 - Precision: 0.8516\n",
      "1311/1311 [==============================] - 265s 202ms/step - loss: 0.5815 - accuracy: 0.8356 - auc: 0.9867 - val_loss: 0.5472 - val_accuracy: 0.8438 - val_auc: 0.9890 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.8529 - auc: 0.9890\n",
      "Epoch 3: accuracy improved from 0.83557 to 0.85294, saving model to ./mish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "Epoch 3 - Top-5 Accuracy: 1.0000 - Precision: 0.8516\n",
      "1311/1311 [==============================] - 272s 207ms/step - loss: 0.5126 - accuracy: 0.8529 - auc: 0.9890 - val_loss: 0.5551 - val_accuracy: 0.8438 - val_auc: 0.9861 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.8646 - auc: 0.9906\n",
      "Epoch 4: accuracy improved from 0.85294 to 0.86465, saving model to ./mish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n",
      "Epoch 4 - Top-5 Accuracy: 1.0000 - Precision: 0.8516\n",
      "1311/1311 [==============================] - 159s 121ms/step - loss: 0.4612 - accuracy: 0.8646 - auc: 0.9906 - val_loss: 0.3742 - val_accuracy: 0.8438 - val_auc: 0.9937 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.8725 - auc: 0.9912\n",
      "Epoch 5: accuracy improved from 0.86465 to 0.87251, saving model to ./mish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n",
      "Epoch 5 - Top-5 Accuracy: 1.0000 - Precision: 0.8875\n",
      "1311/1311 [==============================] - 197s 150ms/step - loss: 0.4387 - accuracy: 0.8725 - auc: 0.9912 - val_loss: 0.4181 - val_accuracy: 0.9062 - val_auc: 0.9941 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "   1/1311 [..............................] - ETA: 3:31 - loss: 0.2648 - accuracy: 0.9375 - auc: 0.9988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.8805 - auc: 0.9921\n",
      "Epoch 6: accuracy improved from 0.87251 to 0.88052, saving model to ./mish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n",
      "Epoch 6 - Top-5 Accuracy: 1.0000 - Precision: 0.9292\n",
      "1311/1311 [==============================] - 160s 122ms/step - loss: 0.4374 - accuracy: 0.8805 - auc: 0.9921 - val_loss: 0.4266 - val_accuracy: 0.8750 - val_auc: 0.9951 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.8808 - auc: 0.9923\n",
      "Epoch 7: accuracy improved from 0.88052 to 0.88081, saving model to ./mish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 7 - Top-5 Accuracy: 1.0000 - Precision: 0.8969\n",
      "1311/1311 [==============================] - 146s 111ms/step - loss: 0.4531 - accuracy: 0.8808 - auc: 0.9923 - val_loss: 0.5833 - val_accuracy: 0.8750 - val_auc: 0.9775 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "   1/1311 [..............................] - ETA: 2:33 - loss: 0.5625 - accuracy: 0.7812 - auc: 0.9874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.8875 - auc: 0.9929\n",
      "Epoch 8: accuracy improved from 0.88081 to 0.88746, saving model to ./mish.h5\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Epoch 8 - Top-5 Accuracy: 1.0000 - Precision: 0.9542\n",
      "1311/1311 [==============================] - 88s 67ms/step - loss: 0.4070 - accuracy: 0.8875 - auc: 0.9929 - val_loss: 0.4401 - val_accuracy: 0.9062 - val_auc: 0.9925 - lr: 0.0010\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.8919 - auc: 0.9932\n",
      "Epoch 9: accuracy improved from 0.88746 to 0.89194, saving model to ./mish.h5\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 9 - Top-5 Accuracy: 1.0000 - Precision: 0.8917\n",
      "1311/1311 [==============================] - 85s 65ms/step - loss: 0.3994 - accuracy: 0.8919 - auc: 0.9932 - val_loss: 0.4230 - val_accuracy: 0.8438 - val_auc: 0.9932 - lr: 0.0010\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4016 - accuracy: 0.8930 - auc: 0.9930\n",
      "Epoch 10: accuracy improved from 0.89194 to 0.89304, saving model to ./mish.h5\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Epoch 10 - Top-5 Accuracy: 1.0000 - Precision: 0.8854\n",
      "1311/1311 [==============================] - 87s 66ms/step - loss: 0.4016 - accuracy: 0.8930 - auc: 0.9930 - val_loss: 0.5435 - val_accuracy: 0.8438 - val_auc: 0.9893 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8971 - auc: 0.9935\n",
      "Epoch 11: accuracy improved from 0.89304 to 0.89712, saving model to ./mish.h5\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Epoch 11 - Top-5 Accuracy: 1.0000 - Precision: 0.8969\n",
      "1311/1311 [==============================] - 85s 65ms/step - loss: 0.3851 - accuracy: 0.8971 - auc: 0.9935 - val_loss: 0.4960 - val_accuracy: 0.8438 - val_auc: 0.9919 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8983 - auc: 0.9941\n",
      "Epoch 12: accuracy improved from 0.89712 to 0.89826, saving model to ./mish.h5\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Epoch 12 - Top-5 Accuracy: 1.0000 - Precision: 0.8542\n",
      "1311/1311 [==============================] - 87s 66ms/step - loss: 0.3796 - accuracy: 0.8983 - auc: 0.9941 - val_loss: 0.3556 - val_accuracy: 0.8438 - val_auc: 0.9952 - lr: 0.0010\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "final = original_model.fit(\n",
    "    image,\n",
    "    steps_per_epoch=len(image),\n",
    "    epochs=30,\n",
    "    validation_data=(validate_data_1, validate_labels),\n",
    "    validation_steps=len(validate_data_1),\n",
    "    verbose=1,\n",
    "    callbacks=callbs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267c3af-9966-4a29-8117-8e65505ffa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angle boot': 0,\n",
       " 'Bag': 1,\n",
       " 'Coat': 2,\n",
       " 'Dress': 3,\n",
       " 'Pullover': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'T-shirt': 8,\n",
       " 'Trouser': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b35d69a-77d7-4c8c-af93-8f3766c98097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Calculate top-5 accuracy\n",
    "    top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "    top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "\n",
    "    return top_5_accuracy, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c36fcf-e48f-46da-9b7f-4347dbbb947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 01:57:54.779624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 376ms/step - loss: 0.3769 - accuracy: 0.8750 - auc: 0.9948\n",
      "Test loss: 0.37690556049346924\n",
      "Test accuracy: 0.875\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      " Top-5 Accuracy: 1.0000\n",
      "Precision: 0.9125\n"
     ]
    }
   ],
   "source": [
    "prediction = original_model.evaluate(X_test , Y_test,verbose=1)\n",
    "print('Test loss:', prediction[0])\n",
    "print('Test accuracy:', prediction[1])\n",
    "\n",
    "predictions = original_model.predict(X_test)\n",
    "top_5_accuracy, precision = calculate_metrics(np.argmax(Y_test, axis=1), predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f' Top-5 Accuracy: {top_5_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4aef46e-dae6-47cf-93e5-33ad3ce2885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = final.history\n",
    "h.keys()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.title(\"Loss vs Acc\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
