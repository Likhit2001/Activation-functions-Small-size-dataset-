{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82494a0c-f7d4-4359-b5f9-3ed922e28f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.13.0\n",
      "GPU is  Available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"tensorflow version : {tf.__version__}\")\n",
    "# print(f\"keras version : {tensorflow.keras.__version__}\")\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is \" , \"Available\" if gpu else \"NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf95bbb1-3ae6-43ec-a7f0-6605be48ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import precision_score\n",
    "from tensorflow.keras import regularizers\n",
    "import shutil\n",
    "import glob\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Dense\n",
    "from keras.layers import Conv2D , GlobalAveragePooling2D , MaxPooling2D,Dropout , Flatten , Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.framework.func_graph import flatten\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import  InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import  preprocess_input\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b75f63-fbf8-4a65-862f-a927dd2ee984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('cat', 5000), ('dog', 5000), ('truck', 5000), ('bird', 5000), ('airplane', 5000), ('ship', 5000), ('frog', 5000), ('horse', 5000), ('deer', 5000), ('automobile', 5000)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"data\"\n",
    "number_of_images = {}\n",
    "\n",
    "for dir in os.listdir(root_dir):\n",
    "    # Ignore .DS_Store files\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Check if the item is a directory before listing its contents\n",
    "    if os.path.isdir(os.path.join(root_dir, dir)):\n",
    "        number_of_images[dir] = len(os.listdir(os.path.join(root_dir, dir)))\n",
    "\n",
    "print(number_of_images.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917d50d1-0d00-470f-892b-0a2e323f8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldercreation (path , split) :\n",
    "    if not os.path.exists('./'+path):\n",
    "      os.mkdir('./'+path)\n",
    "\n",
    "      for dir in os.listdir(root_dir):\n",
    "        if dir == '.DS_Store':\n",
    "           continue\n",
    "            \n",
    "        os.makedirs('./'+path+\"/\"+dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)) , size = (math.floor(split * number_of_images[dir])-5) , replace=False):\n",
    "          Original = os.path.join(root_dir,dir,img)\n",
    "          Destination =os.path.join('./'+path , dir)\n",
    "          shutil.copy(Original,Destination)\n",
    "          # os.remove(Original)\n",
    "\n",
    "    else:\n",
    "      print(\"The folder exsist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d030332f-42c5-45fe-a9df-0b2a9b5017d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder exsist\n",
      "The folder exsist\n",
      "The folder exsist\n"
     ]
    }
   ],
   "source": [
    "foldercreation(\"train_data\",0.7)\n",
    "foldercreation(\"validation_data\",0.15)\n",
    "foldercreation(\"test_data\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1199e693-d2a0-4659-8991-706065051243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = ImageDataGenerator (\n",
    "                                     \n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      preprocessing_function= preprocess_input,\n",
    "                                )\n",
    "\n",
    "image=image_data.flow_from_directory(directory=\"train_data\" ,\n",
    "                                       target_size=(28,28),\n",
    "                                       batch_size=32,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964c9fed-0872-4410-9a39-496bbb9903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2 (path):\n",
    "  image_data = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "  image = image_data.flow_from_directory(directory = path,\n",
    "                                         target_size=(28,28),\n",
    "                                         batch_size = 32,\n",
    "                                         shuffle=True,\n",
    "                                         class_mode = \"categorical\")\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd18e7b0-ba7d-4a5f-980a-7dc3073d0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7450 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_test =\"test_data\"\n",
    "test_data = preprocessing2(path_test)\n",
    "X_test , Y_test = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304013d9-6d94-42dc-8e5f-6e07aa03aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7450 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_validate=\"validation_data\"\n",
    "validate_data = preprocessing2(path_validate)\n",
    "validate_data_1 , validate_labels = validate_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9579cd-cd00-4c61-bf70-6e9c4fc0a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def swish(x):\n",
    "    return x * tf.nn.sigmoid(x)\n",
    "\n",
    "def model_layer_1 (inputs,filters):\n",
    "\n",
    "\n",
    "  convo_2x2 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='swish')(inputs)\n",
    "  convo_3x3 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='swish')(inputs)\n",
    "  pool_conv = Conv2D(filters=filters[2], kernel_size=(3,3), padding='same', activation='swish')(inputs)\n",
    "\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([convo_2x2, convo_3x3, pool_conv])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_2 (inputs,filters):\n",
    "\n",
    "\n",
    "\n",
    "  convo_3x3 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='swish')(inputs)\n",
    "  pool_3x3 =MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(convo_3x3)\n",
    "\n",
    "  convo_5x5 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='swish')(inputs)\n",
    "  pool_5x5 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(convo_5x5)\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([pool_3x3, pool_5x5])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_3 (inputs,filters):\n",
    "    \n",
    "  convo_1x1 = Conv2D(filters=filters[0], kernel_size=(3,3), padding='same', activation='swish')(inputs)\n",
    "  pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "  outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "# def model_layer_5 (inputs,filters):\n",
    "    \n",
    "#   convo_1x1 = Conv2D(filters=filters[0], kernel_size=(5,5), padding='same', activation='relu')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "# def model_layer_6 (inputs):\n",
    "    \n",
    "#   pool_3x3 = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, pool_3x3])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fb6b60-b00f-4849-a8f0-cd2f02b411fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:40:18.126380: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-12-20 12:40:18.126418: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-20 12:40:18.126434: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-20 12:40:18.126488: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-20 12:40:18.126511: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "# define input tensor\n",
    "\n",
    "input_tensor = Input(shape=(28, 28, 3))\n",
    "\n",
    "\n",
    "\n",
    "original_model = model_layer_3(input_tensor,[128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "\n",
    "\n",
    "original_model = model_layer_1(original_model,[32,64,128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2),padding='same')(original_model)\n",
    "original_model = model_layer_2(original_model,[128,64])\n",
    "\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "original_model = model_layer_3(original_model,[128])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc7fa87-ee6b-492e-8b39-c938722e9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_model = Flatten()(original_model)\n",
    "\n",
    "original_model = Dense(512, activation='swish' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dense(256, activation='swish' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dropout(0.5)(original_model)\n",
    "\n",
    "output_tensor = Dense(10, activation='softmax' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "\n",
    "original_model = Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040bd7f7-895c-4e21-9194-c500ec6c59a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 28, 28, 3)            0         ['input_1[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 28, 28, 128)          3584      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 28, 28, 131)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 131)          0         ['concatenate[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)           16800     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)           75520     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 128)          151040    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 14, 14, 224)          0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_2[0][0]',            \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 224)            0         ['concatenate_1[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)            114816    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)             129088    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)            0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 7, 7, 192)            0         ['max_pooling2d_3[0][0]',     \n",
      " )                                                                   'max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 192)            0         ['concatenate_2[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 4, 4, 192)            0         ['max_pooling2d_5[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)            221312    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 4, 4, 320)            0         ['max_pooling2d_6[0][0]',     \n",
      " )                                                                   'conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 5120)                 0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  2621952   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 10)                   2570      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3468010 (13.23 MB)\n",
      "Trainable params: 3468010 (13.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909495f2-933b-4cfa-826b-bbb1890983f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "original_model.compile(optimizer= opt ,\n",
    "              loss= keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy' , 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab155de-6383-4f99-adce-e2d575457f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor=\"accuracy\",\n",
    "                          min_delta=0.01 , patience=3,\n",
    "                          verbose=1,\n",
    "                          mode=\"auto\")\n",
    "modelcheckpoint = ModelCheckpoint(monitor=\"accuracy\",\n",
    "                                  filepath = \"./swish.h5\",\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  mode =\"auto\"\n",
    "                                  )\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-3)\n",
    "\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        predictions = self.model.predict(x_val)\n",
    "        \n",
    "        # Calculate top-5 accuracy\n",
    "        top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "        true_labels = np.argmax(y_val, axis=1)\n",
    "        top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Top-5 Accuracy: {top_5_accuracy:.4f} - Precision: {precision:.4f}')\n",
    "\n",
    "\n",
    "metrics_callback = MetricsCallback(validation_data=(validate_data_1, validate_labels))\n",
    "\n",
    "callbs = [earlystop,modelcheckpoint,lr_scheduler,metrics_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fdd759-3059-4565-912b-aa46961a283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:40:20.363184: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.8203 - accuracy: 0.4276 - auc: 0.8560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:41:55.594278: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.42758, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 214ms/step\n",
      "Epoch 1 - Top-5 Accuracy: 1.0000 - Precision: 0.6771\n",
      "1093/1093 [==============================] - 98s 88ms/step - loss: 1.8203 - accuracy: 0.4276 - auc: 0.8560 - val_loss: 1.3261 - val_accuracy: 0.6562 - val_auc: 0.9290 - lr: 0.0010\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:41:57.788131: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.3437 - accuracy: 0.5824 - auc: 0.9205\n",
      "Epoch 2: accuracy improved from 0.42758 to 0.58243, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Epoch 2 - Top-5 Accuracy: 0.9688 - Precision: 0.7979\n",
      "1093/1093 [==============================] - 90s 82ms/step - loss: 1.3437 - accuracy: 0.5824 - auc: 0.9205 - val_loss: 1.0632 - val_accuracy: 0.7500 - val_auc: 0.9565 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "   1/1093 [..............................] - ETA: 1:43 - loss: 1.6247 - accuracy: 0.4688 - auc: 0.8835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.1998 - accuracy: 0.6447 - auc: 0.9408\n",
      "Epoch 3: accuracy improved from 0.58243 to 0.64475, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "Epoch 3 - Top-5 Accuracy: 1.0000 - Precision: 0.8385\n",
      "1093/1093 [==============================] - 90s 82ms/step - loss: 1.1998 - accuracy: 0.6447 - auc: 0.9408 - val_loss: 0.9667 - val_accuracy: 0.7812 - val_auc: 0.9671 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0864 - accuracy: 0.6863 - auc: 0.9525\n",
      "Epoch 4: accuracy improved from 0.64475 to 0.68629, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch 4 - Top-5 Accuracy: 1.0000 - Precision: 0.7656\n",
      "1093/1093 [==============================] - 91s 83ms/step - loss: 1.0864 - accuracy: 0.6863 - auc: 0.9525 - val_loss: 0.9396 - val_accuracy: 0.6875 - val_auc: 0.9671 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0139 - accuracy: 0.7122 - auc: 0.9594\n",
      "Epoch 5: accuracy improved from 0.68629 to 0.71219, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "Epoch 5 - Top-5 Accuracy: 1.0000 - Precision: 0.8167\n",
      "1093/1093 [==============================] - 91s 83ms/step - loss: 1.0139 - accuracy: 0.7122 - auc: 0.9594 - val_loss: 0.8672 - val_accuracy: 0.7500 - val_auc: 0.9754 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.9502 - accuracy: 0.7348 - auc: 0.9648\n",
      "Epoch 6: accuracy improved from 0.71219 to 0.73482, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "Epoch 6 - Top-5 Accuracy: 1.0000 - Precision: 0.8250\n",
      "1093/1093 [==============================] - 89s 81ms/step - loss: 0.9502 - accuracy: 0.7348 - auc: 0.9648 - val_loss: 0.8865 - val_accuracy: 0.7500 - val_auc: 0.9718 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.9044 - accuracy: 0.7498 - auc: 0.9683\n",
      "Epoch 7: accuracy improved from 0.73482 to 0.74976, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "Epoch 7 - Top-5 Accuracy: 1.0000 - Precision: 0.8646\n",
      "1093/1093 [==============================] - 100s 92ms/step - loss: 0.9044 - accuracy: 0.7498 - auc: 0.9683 - val_loss: 0.8409 - val_accuracy: 0.8125 - val_auc: 0.9737 - lr: 0.0010\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.7658 - auc: 0.9717\n",
      "Epoch 8: accuracy improved from 0.74976 to 0.76578, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "Epoch 8 - Top-5 Accuracy: 0.9688 - Precision: 0.8375\n",
      "1093/1093 [==============================] - 108s 99ms/step - loss: 0.8415 - accuracy: 0.7658 - auc: 0.9717 - val_loss: 0.8817 - val_accuracy: 0.7188 - val_auc: 0.9604 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.8252 - accuracy: 0.7729 - auc: 0.9735\n",
      "Epoch 9: accuracy improved from 0.76578 to 0.77293, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 123ms/step\n",
      "Epoch 9 - Top-5 Accuracy: 1.0000 - Precision: 0.9062\n",
      "1093/1093 [==============================] - 91s 83ms/step - loss: 0.8252 - accuracy: 0.7729 - auc: 0.9735 - val_loss: 0.6296 - val_accuracy: 0.8750 - val_auc: 0.9908 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.8084 - accuracy: 0.7830 - auc: 0.9752\n",
      "Epoch 10: accuracy improved from 0.77293 to 0.78300, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 10 - Top-5 Accuracy: 1.0000 - Precision: 0.8385\n",
      "1093/1093 [==============================] - 89s 81ms/step - loss: 0.8084 - accuracy: 0.7830 - auc: 0.9752 - val_loss: 0.6457 - val_accuracy: 0.8125 - val_auc: 0.9901 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.8138 - accuracy: 0.7930 - auc: 0.9767\n",
      "Epoch 11: accuracy improved from 0.78300 to 0.79296, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch 11 - Top-5 Accuracy: 1.0000 - Precision: 0.9427\n",
      "1093/1093 [==============================] - 85s 78ms/step - loss: 0.8138 - accuracy: 0.7930 - auc: 0.9767 - val_loss: 0.6740 - val_accuracy: 0.9062 - val_auc: 0.9733 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.7545 - accuracy: 0.8035 - auc: 0.9792\n",
      "Epoch 12: accuracy improved from 0.79296 to 0.80355, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 12 - Top-5 Accuracy: 0.9688 - Precision: 0.8500\n",
      "1093/1093 [==============================] - 85s 77ms/step - loss: 0.7545 - accuracy: 0.8035 - auc: 0.9792 - val_loss: 0.6106 - val_accuracy: 0.8438 - val_auc: 0.9883 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "   1/1093 [..............................] - ETA: 2:13 - loss: 0.7849 - accuracy: 0.7188 - auc: 0.9779"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 0.7200 - accuracy: 0.8086 - auc: 0.9803\n",
      "Epoch 13: accuracy improved from 0.80355 to 0.80856, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Epoch 13 - Top-5 Accuracy: 1.0000 - Precision: 0.9062\n",
      "1093/1093 [==============================] - 85s 78ms/step - loss: 0.7200 - accuracy: 0.8086 - auc: 0.9803 - val_loss: 0.5878 - val_accuracy: 0.8438 - val_auc: 0.9887 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.7208 - accuracy: 0.8159 - auc: 0.9810\n",
      "Epoch 14: accuracy improved from 0.80856 to 0.81588, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "Epoch 14 - Top-5 Accuracy: 1.0000 - Precision: 0.8594\n",
      "1093/1093 [==============================] - 92s 84ms/step - loss: 0.7208 - accuracy: 0.8159 - auc: 0.9810 - val_loss: 0.7949 - val_accuracy: 0.7812 - val_auc: 0.9675 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.8203 - auc: 0.9816\n",
      "Epoch 15: accuracy improved from 0.81588 to 0.82031, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Epoch 15 - Top-5 Accuracy: 1.0000 - Precision: 0.7839\n",
      "1093/1093 [==============================] - 92s 84ms/step - loss: 0.7375 - accuracy: 0.8203 - auc: 0.9816 - val_loss: 0.7588 - val_accuracy: 0.7812 - val_auc: 0.9807 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.8252 - auc: 0.9826\n",
      "Epoch 16: accuracy improved from 0.82031 to 0.82518, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Epoch 16 - Top-5 Accuracy: 1.0000 - Precision: 0.8812\n",
      "1093/1093 [==============================] - 100s 91ms/step - loss: 0.6967 - accuracy: 0.8252 - auc: 0.9826 - val_loss: 0.7155 - val_accuracy: 0.8438 - val_auc: 0.9819 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.8276 - auc: 0.9837\n",
      "Epoch 17: accuracy improved from 0.82518 to 0.82755, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "Epoch 17 - Top-5 Accuracy: 1.0000 - Precision: 0.8708\n",
      "1093/1093 [==============================] - 106s 97ms/step - loss: 0.6732 - accuracy: 0.8276 - auc: 0.9837 - val_loss: 0.5524 - val_accuracy: 0.8438 - val_auc: 0.9926 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.8323 - auc: 0.9841\n",
      "Epoch 18: accuracy improved from 0.82755 to 0.83233, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Epoch 18 - Top-5 Accuracy: 1.0000 - Precision: 0.8917\n",
      "1093/1093 [==============================] - 74s 68ms/step - loss: 0.6804 - accuracy: 0.8323 - auc: 0.9841 - val_loss: 0.6673 - val_accuracy: 0.8750 - val_auc: 0.9869 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.8397 - auc: 0.9847\n",
      "Epoch 19: accuracy improved from 0.83233 to 0.83966, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Epoch 19 - Top-5 Accuracy: 1.0000 - Precision: 0.9229\n",
      "1093/1093 [==============================] - 70s 64ms/step - loss: 0.6643 - accuracy: 0.8397 - auc: 0.9847 - val_loss: 0.6822 - val_accuracy: 0.9062 - val_auc: 0.9746 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.8421 - auc: 0.9857\n",
      "Epoch 20: accuracy improved from 0.83966 to 0.84209, saving model to ./swish.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Epoch 20 - Top-5 Accuracy: 1.0000 - Precision: 0.8385\n",
      "1093/1093 [==============================] - 74s 68ms/step - loss: 0.6608 - accuracy: 0.8421 - auc: 0.9857 - val_loss: 0.7093 - val_accuracy: 0.7812 - val_auc: 0.9724 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.8480 - auc: 0.9859\n",
      "Epoch 21: accuracy improved from 0.84209 to 0.84804, saving model to ./swish.h5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch 21 - Top-5 Accuracy: 1.0000 - Precision: 0.9368\n",
      "1093/1093 [==============================] - 64s 58ms/step - loss: 0.6462 - accuracy: 0.8480 - auc: 0.9859 - val_loss: 0.5042 - val_accuracy: 0.9062 - val_auc: 0.9939 - lr: 0.0010\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.8494 - auc: 0.9867\n",
      "Epoch 22: accuracy improved from 0.84804 to 0.84936, saving model to ./swish.h5\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch 22 - Top-5 Accuracy: 1.0000 - Precision: 0.8385\n",
      "1093/1093 [==============================] - 62s 56ms/step - loss: 0.6396 - accuracy: 0.8494 - auc: 0.9867 - val_loss: 1.2101 - val_accuracy: 0.6875 - val_auc: 0.9547 - lr: 0.0010\n",
      "Epoch 22: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "final = original_model.fit(\n",
    "    image,\n",
    "    steps_per_epoch=len(image),\n",
    "    epochs=30,\n",
    "    validation_data=(validate_data_1, validate_labels),\n",
    "    validation_steps=len(validate_data_1),\n",
    "    verbose=1,\n",
    "    callbacks=callbs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267c3af-9966-4a29-8117-8e65505ffa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b35d69a-77d7-4c8c-af93-8f3766c98097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Calculate top-5 accuracy\n",
    "    top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "    top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "\n",
    "    return top_5_accuracy, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c36fcf-e48f-46da-9b7f-4347dbbb947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 13:12:27.707202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 539ms/step - loss: 1.0608 - accuracy: 0.6875 - auc: 0.9646\n",
      "Test loss: 1.0607926845550537\n",
      "Test accuracy: 0.6875\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      " Top-5 Accuracy: 0.9688\n",
      "Precision: 0.7839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "prediction = original_model.evaluate(X_test , Y_test,verbose=1)\n",
    "print('Test loss:', prediction[0])\n",
    "print('Test accuracy:', prediction[1])\n",
    "\n",
    "predictions = original_model.predict(X_test)\n",
    "top_5_accuracy, precision = calculate_metrics(np.argmax(Y_test, axis=1), predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f' Top-5 Accuracy: {top_5_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4aef46e-dae6-47cf-93e5-33ad3ce2885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = final.history\n",
    "h.keys()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.title(\"Loss vs Acc\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
