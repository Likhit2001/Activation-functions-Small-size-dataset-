{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82494a0c-f7d4-4359-b5f9-3ed922e28f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.13.0\n",
      "GPU is  Available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"tensorflow version : {tf.__version__}\")\n",
    "# print(f\"keras version : {tensorflow.keras.__version__}\")\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is \" , \"Available\" if gpu else \"NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf95bbb1-3ae6-43ec-a7f0-6605be48ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import precision_score\n",
    "from tensorflow.keras import regularizers\n",
    "import shutil\n",
    "import glob\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Dense\n",
    "from keras.layers import Conv2D , GlobalAveragePooling2D , MaxPooling2D,Dropout , Flatten , Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.framework.func_graph import flatten\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import  InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import  preprocess_input\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b75f63-fbf8-4a65-862f-a927dd2ee984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('cat', 5000), ('dog', 5000), ('truck', 5000), ('bird', 5000), ('airplane', 5000), ('ship', 5000), ('frog', 5000), ('horse', 5000), ('deer', 5000), ('automobile', 5000)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"data\"\n",
    "number_of_images = {}\n",
    "\n",
    "for dir in os.listdir(root_dir):\n",
    "    # Ignore .DS_Store files\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Check if the item is a directory before listing its contents\n",
    "    if os.path.isdir(os.path.join(root_dir, dir)):\n",
    "        number_of_images[dir] = len(os.listdir(os.path.join(root_dir, dir)))\n",
    "\n",
    "print(number_of_images.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917d50d1-0d00-470f-892b-0a2e323f8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldercreation (path , split) :\n",
    "    if not os.path.exists('./'+path):\n",
    "      os.mkdir('./'+path)\n",
    "\n",
    "      for dir in os.listdir(root_dir):\n",
    "        if dir == '.DS_Store':\n",
    "           continue\n",
    "            \n",
    "        os.makedirs('./'+path+\"/\"+dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)) , size = (math.floor(split * number_of_images[dir])-5) , replace=False):\n",
    "          Original = os.path.join(root_dir,dir,img)\n",
    "          Destination =os.path.join('./'+path , dir)\n",
    "          shutil.copy(Original,Destination)\n",
    "          # os.remove(Original)\n",
    "\n",
    "    else:\n",
    "      print(\"The folder exsist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d030332f-42c5-45fe-a9df-0b2a9b5017d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder exsist\n",
      "The folder exsist\n",
      "The folder exsist\n"
     ]
    }
   ],
   "source": [
    "foldercreation(\"train_data\",0.7)\n",
    "foldercreation(\"validation_data\",0.15)\n",
    "foldercreation(\"test_data\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1199e693-d2a0-4659-8991-706065051243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = ImageDataGenerator (\n",
    "                                     \n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      preprocessing_function= preprocess_input,\n",
    "                                )\n",
    "\n",
    "image=image_data.flow_from_directory(directory=\"train_data\" ,\n",
    "                                       target_size=(28,28),\n",
    "                                       batch_size=32,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964c9fed-0872-4410-9a39-496bbb9903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2 (path):\n",
    "  image_data = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "  image = image_data.flow_from_directory(directory = path,\n",
    "                                         target_size=(28,28),\n",
    "                                         batch_size = 32,\n",
    "                                         shuffle=True,\n",
    "                                         class_mode = \"categorical\")\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd18e7b0-ba7d-4a5f-980a-7dc3073d0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7450 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_test =\"test_data\"\n",
    "test_data = preprocessing2(path_test)\n",
    "X_test , Y_test = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304013d9-6d94-42dc-8e5f-6e07aa03aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7450 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_validate=\"validation_data\"\n",
    "validate_data = preprocessing2(path_validate)\n",
    "validate_data_1 , validate_labels = validate_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9579cd-cd00-4c61-bf70-6e9c4fc0a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus = tf.nn.softplus\n",
    "def model_layer_1 (inputs,filters):\n",
    "\n",
    "\n",
    "  convo_2x2 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='softplus')(inputs)\n",
    "  convo_3x3 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='softplus')(inputs)\n",
    "  pool_conv = Conv2D(filters=filters[2], kernel_size=(3,3), padding='same', activation='softplus')(inputs)\n",
    "\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([convo_2x2, convo_3x3, pool_conv])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_2 (inputs,filters):\n",
    "\n",
    "\n",
    "\n",
    "  convo_3x3 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='softplus')(inputs)\n",
    "  pool_3x3 =MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(convo_3x3)\n",
    "\n",
    "  convo_5x5 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='softplus')(inputs)\n",
    "  pool_5x5 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(convo_5x5)\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([pool_3x3, pool_5x5])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_3 (inputs,filters):\n",
    "    \n",
    "  convo_1x1 = Conv2D(filters=filters[0], kernel_size=(3,3), padding='same', activation='softplus')(inputs)\n",
    "  pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "  outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "# def model_layer_5 (inputs,filters):\n",
    "    \n",
    "#   convo_1x1 = Conv2D(filters=filters[0], kernel_size=(5,5), padding='same', activation='relu')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "# def model_layer_6 (inputs):\n",
    "    \n",
    "#   pool_3x3 = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, pool_3x3])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fb6b60-b00f-4849-a8f0-cd2f02b411fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:40:11.302663: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-12-20 12:40:11.302694: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-20 12:40:11.302706: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-20 12:40:11.302741: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-20 12:40:11.302763: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "# define input tensor\n",
    "\n",
    "input_tensor = Input(shape=(28, 28, 3))\n",
    "\n",
    "\n",
    "original_model = model_layer_3(input_tensor,[128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "\n",
    "\n",
    "original_model = model_layer_1(original_model,[32,64,128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2),padding='same')(original_model)\n",
    "original_model = model_layer_2(original_model,[128,64])\n",
    "\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "original_model = model_layer_3(original_model,[128])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc7fa87-ee6b-492e-8b39-c938722e9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_model = Flatten()(original_model)\n",
    "original_model = Dense(512, activation='softplus' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dense(256, activation='softplus' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dropout(0.5)(original_model)\n",
    "\n",
    "output_tensor = Dense(10, activation='softmax' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "\n",
    "original_model = Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040bd7f7-895c-4e21-9194-c500ec6c59a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 28, 28, 3)            0         ['input_1[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 28, 28, 128)          3584      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 28, 28, 131)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 131)          0         ['concatenate[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)           16800     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)           75520     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 128)          151040    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 14, 14, 224)          0         ['conv2d_1[0][0]',            \n",
      " )                                                                   'conv2d_2[0][0]',            \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 224)            0         ['concatenate_1[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)            114816    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)             129088    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)            0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 7, 7, 192)            0         ['max_pooling2d_3[0][0]',     \n",
      " )                                                                   'max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 192)            0         ['concatenate_2[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 4, 4, 192)            0         ['max_pooling2d_5[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)            221312    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 4, 4, 320)            0         ['max_pooling2d_6[0][0]',     \n",
      " )                                                                   'conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 5120)                 0         ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  2621952   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 10)                   2570      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3468010 (13.23 MB)\n",
      "Trainable params: 3468010 (13.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909495f2-933b-4cfa-826b-bbb1890983f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "original_model.compile(optimizer= opt ,\n",
    "              loss= keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy' , 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab155de-6383-4f99-adce-e2d575457f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor=\"accuracy\",\n",
    "                          min_delta=0.01 , patience=3,\n",
    "                          verbose=1,\n",
    "                          mode=\"auto\")\n",
    "modelcheckpoint = ModelCheckpoint(monitor=\"accuracy\",\n",
    "                                  filepath = \"./softplus.h5\",\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  mode =\"auto\"\n",
    "                                  )\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-3)\n",
    "\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        predictions = self.model.predict(x_val)\n",
    "        \n",
    "        # Calculate top-5 accuracy\n",
    "        top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "        true_labels = np.argmax(y_val, axis=1)\n",
    "        top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Top-5 Accuracy: {top_5_accuracy:.4f} - Precision: {precision:.4f}')\n",
    "\n",
    "\n",
    "metrics_callback = MetricsCallback(validation_data=(validate_data_1, validate_labels))\n",
    "\n",
    "callbs = [earlystop,modelcheckpoint,lr_scheduler,metrics_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fdd759-3059-4565-912b-aa46961a283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:40:13.050160: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 2.6527 - accuracy: 0.1559 - auc: 0.6143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:42:24.654195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.15591, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 234ms/step\n",
      "Epoch 1 - Top-5 Accuracy: 0.8125 - Precision: 0.2231\n",
      "1093/1093 [==============================] - 135s 122ms/step - loss: 2.6527 - accuracy: 0.1559 - auc: 0.6143 - val_loss: 2.1489 - val_accuracy: 0.2812 - val_auc: 0.7374 - lr: 0.0010\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:42:27.129336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.8302 - accuracy: 0.3635 - auc: 0.8197\n",
      "Epoch 2: accuracy improved from 0.15591 to 0.36349, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "Epoch 2 - Top-5 Accuracy: 0.9688 - Precision: 0.4802\n",
      "1093/1093 [==============================] - 131s 119ms/step - loss: 1.8302 - accuracy: 0.3635 - auc: 0.8197 - val_loss: 1.5179 - val_accuracy: 0.4688 - val_auc: 0.8911 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.6337 - accuracy: 0.4355 - auc: 0.8584\n",
      "Epoch 3: accuracy improved from 0.36349 to 0.43554, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "Epoch 3 - Top-5 Accuracy: 0.9375 - Precision: 0.5052\n",
      "1093/1093 [==============================] - 130s 119ms/step - loss: 1.6337 - accuracy: 0.4355 - auc: 0.8584 - val_loss: 1.5163 - val_accuracy: 0.4688 - val_auc: 0.8807 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.5376 - accuracy: 0.4694 - auc: 0.8752\n",
      "Epoch 4: accuracy improved from 0.43554 to 0.46938, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "Epoch 4 - Top-5 Accuracy: 0.9688 - Precision: 0.4365\n",
      "1093/1093 [==============================] - 131s 119ms/step - loss: 1.5376 - accuracy: 0.4694 - auc: 0.8752 - val_loss: 1.4856 - val_accuracy: 0.4375 - val_auc: 0.8898 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "   1/1093 [..............................] - ETA: 3:10 - loss: 1.5747 - accuracy: 0.5000 - auc: 0.8726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.4790 - accuracy: 0.4943 - auc: 0.8855\n",
      "Epoch 5: accuracy improved from 0.46938 to 0.49431, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "Epoch 5 - Top-5 Accuracy: 0.9688 - Precision: 0.4851\n",
      "1093/1093 [==============================] - 139s 127ms/step - loss: 1.4790 - accuracy: 0.4943 - auc: 0.8855 - val_loss: 1.3960 - val_accuracy: 0.4375 - val_auc: 0.9085 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.4296 - accuracy: 0.5105 - auc: 0.8938\n",
      "Epoch 6: accuracy improved from 0.49431 to 0.51047, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "Epoch 6 - Top-5 Accuracy: 0.9688 - Precision: 0.5052\n",
      "1093/1093 [==============================] - 147s 134ms/step - loss: 1.4296 - accuracy: 0.5105 - auc: 0.8938 - val_loss: 1.3741 - val_accuracy: 0.4688 - val_auc: 0.9124 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.3938 - accuracy: 0.5278 - auc: 0.8998\n",
      "Epoch 7: accuracy improved from 0.51047 to 0.52778, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n",
      "Epoch 7 - Top-5 Accuracy: 0.9375 - Precision: 0.6042\n",
      "1093/1093 [==============================] - 130s 119ms/step - loss: 1.3938 - accuracy: 0.5278 - auc: 0.8998 - val_loss: 1.2681 - val_accuracy: 0.5938 - val_auc: 0.9199 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.3607 - accuracy: 0.5409 - auc: 0.9053\n",
      "Epoch 8: accuracy improved from 0.52778 to 0.54092, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n",
      "Epoch 8 - Top-5 Accuracy: 1.0000 - Precision: 0.5260\n",
      "1093/1093 [==============================] - 124s 113ms/step - loss: 1.3607 - accuracy: 0.5409 - auc: 0.9053 - val_loss: 1.4258 - val_accuracy: 0.5312 - val_auc: 0.8985 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.3188 - accuracy: 0.5588 - auc: 0.9110\n",
      "Epoch 9: accuracy improved from 0.54092 to 0.55877, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n",
      "Epoch 9 - Top-5 Accuracy: 0.9688 - Precision: 0.5776\n",
      "1093/1093 [==============================] - 123s 112ms/step - loss: 1.3188 - accuracy: 0.5588 - auc: 0.9110 - val_loss: 1.2822 - val_accuracy: 0.6250 - val_auc: 0.9229 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.3015 - accuracy: 0.5664 - auc: 0.9146\n",
      "Epoch 10: accuracy improved from 0.55877 to 0.56638, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "Epoch 10 - Top-5 Accuracy: 0.9688 - Precision: 0.5521\n",
      "1093/1093 [==============================] - 134s 122ms/step - loss: 1.3015 - accuracy: 0.5664 - auc: 0.9146 - val_loss: 1.2507 - val_accuracy: 0.5938 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.2710 - accuracy: 0.5791 - auc: 0.9184\n",
      "Epoch 11: accuracy improved from 0.56638 to 0.57908, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "Epoch 11 - Top-5 Accuracy: 1.0000 - Precision: 0.7188\n",
      "1093/1093 [==============================] - 142s 130ms/step - loss: 1.2710 - accuracy: 0.5791 - auc: 0.9184 - val_loss: 1.2013 - val_accuracy: 0.6562 - val_auc: 0.9339 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.2533 - accuracy: 0.5842 - auc: 0.9205\n",
      "Epoch 12: accuracy improved from 0.57908 to 0.58418, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 12 - Top-5 Accuracy: 0.9375 - Precision: 0.5260\n",
      "1093/1093 [==============================] - 146s 134ms/step - loss: 1.2533 - accuracy: 0.5842 - auc: 0.9205 - val_loss: 1.4368 - val_accuracy: 0.5625 - val_auc: 0.8937 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "   1/1093 [..............................] - ETA: 2:49 - loss: 1.4754 - accuracy: 0.5000 - auc: 0.8917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.2231 - accuracy: 0.5933 - auc: 0.9247\n",
      "Epoch 13: accuracy improved from 0.58418 to 0.59328, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "Epoch 13 - Top-5 Accuracy: 0.9062 - Precision: 0.5781\n",
      "1093/1093 [==============================] - 97s 89ms/step - loss: 1.2231 - accuracy: 0.5933 - auc: 0.9247 - val_loss: 1.3240 - val_accuracy: 0.5938 - val_auc: 0.9000 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.2026 - accuracy: 0.6029 - auc: 0.9275\n",
      "Epoch 14: accuracy improved from 0.59328 to 0.60295, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 14 - Top-5 Accuracy: 1.0000 - Precision: 0.5589\n",
      "1093/1093 [==============================] - 104s 95ms/step - loss: 1.2026 - accuracy: 0.6029 - auc: 0.9275 - val_loss: 1.3079 - val_accuracy: 0.5938 - val_auc: 0.9199 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.1828 - accuracy: 0.6074 - auc: 0.9305\n",
      "Epoch 15: accuracy improved from 0.60295 to 0.60738, saving model to ./softplus.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "Epoch 15 - Top-5 Accuracy: 0.9688 - Precision: 0.4792\n",
      "1093/1093 [==============================] - 87s 79ms/step - loss: 1.1828 - accuracy: 0.6074 - auc: 0.9305 - val_loss: 1.2274 - val_accuracy: 0.5312 - val_auc: 0.9266 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "1093/1093 [==============================] - ETA: 0s - loss: 1.1642 - accuracy: 0.6151 - auc: 0.9326\n",
      "Epoch 16: accuracy improved from 0.60738 to 0.61505, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Epoch 16 - Top-5 Accuracy: 0.9375 - Precision: 0.6250\n",
      "1093/1093 [==============================] - 74s 67ms/step - loss: 1.1642 - accuracy: 0.6151 - auc: 0.9326 - val_loss: 1.2227 - val_accuracy: 0.6250 - val_auc: 0.9274 - lr: 0.0010\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.1422 - accuracy: 0.6281 - auc: 0.9358\n",
      "Epoch 17: accuracy improved from 0.61505 to 0.62807, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Epoch 17 - Top-5 Accuracy: 0.9688 - Precision: 0.7083\n",
      "1093/1093 [==============================] - 65s 60ms/step - loss: 1.1422 - accuracy: 0.6281 - auc: 0.9358 - val_loss: 1.0943 - val_accuracy: 0.6562 - val_auc: 0.9419 - lr: 0.0010\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.1215 - accuracy: 0.6355 - auc: 0.9377\n",
      "Epoch 18: accuracy improved from 0.62807 to 0.63554, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Epoch 18 - Top-5 Accuracy: 0.9375 - Precision: 0.6797\n",
      "1093/1093 [==============================] - 67s 61ms/step - loss: 1.1215 - accuracy: 0.6355 - auc: 0.9377 - val_loss: 1.1162 - val_accuracy: 0.6250 - val_auc: 0.9398 - lr: 0.0010\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0984 - accuracy: 0.6415 - auc: 0.9404\n",
      "Epoch 19: accuracy improved from 0.63554 to 0.64146, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Epoch 19 - Top-5 Accuracy: 0.9062 - Precision: 0.6125\n",
      "1093/1093 [==============================] - 53s 49ms/step - loss: 1.0984 - accuracy: 0.6415 - auc: 0.9404 - val_loss: 1.1402 - val_accuracy: 0.5625 - val_auc: 0.9347 - lr: 0.0010\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0884 - accuracy: 0.6497 - auc: 0.9418\n",
      "Epoch 20: accuracy improved from 0.64146 to 0.64973, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Epoch 20 - Top-5 Accuracy: 0.9688 - Precision: 0.5052\n",
      "1093/1093 [==============================] - 58s 53ms/step - loss: 1.0884 - accuracy: 0.6497 - auc: 0.9418 - val_loss: 1.3243 - val_accuracy: 0.5625 - val_auc: 0.9247 - lr: 0.0010\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0787 - accuracy: 0.6541 - auc: 0.9431\n",
      "Epoch 21: accuracy improved from 0.64973 to 0.65413, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Epoch 21 - Top-5 Accuracy: 0.9688 - Precision: 0.6042\n",
      "1093/1093 [==============================] - 71s 65ms/step - loss: 1.0787 - accuracy: 0.6541 - auc: 0.9431 - val_loss: 1.0708 - val_accuracy: 0.6250 - val_auc: 0.9492 - lr: 0.0010\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0571 - accuracy: 0.6612 - auc: 0.9454\n",
      "Epoch 22: accuracy improved from 0.65413 to 0.66123, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Epoch 22 - Top-5 Accuracy: 1.0000 - Precision: 0.6214\n",
      "1093/1093 [==============================] - 72s 66ms/step - loss: 1.0571 - accuracy: 0.6612 - auc: 0.9454 - val_loss: 1.0937 - val_accuracy: 0.6250 - val_auc: 0.9462 - lr: 0.0010\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0398 - accuracy: 0.6629 - auc: 0.9469\n",
      "Epoch 23: accuracy improved from 0.66123 to 0.66295, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Epoch 23 - Top-5 Accuracy: 1.0000 - Precision: 0.6042\n",
      "1093/1093 [==============================] - 72s 66ms/step - loss: 1.0398 - accuracy: 0.6629 - auc: 0.9469 - val_loss: 1.0973 - val_accuracy: 0.5938 - val_auc: 0.9457 - lr: 0.0010\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0240 - accuracy: 0.6737 - auc: 0.9487\n",
      "Epoch 24: accuracy improved from 0.66295 to 0.67373, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Epoch 24 - Top-5 Accuracy: 0.9375 - Precision: 0.5813\n",
      "1093/1093 [==============================] - 62s 56ms/step - loss: 1.0240 - accuracy: 0.6737 - auc: 0.9487 - val_loss: 1.0775 - val_accuracy: 0.5938 - val_auc: 0.9437 - lr: 0.0010\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 1.0142 - accuracy: 0.6772 - auc: 0.9501\n",
      "Epoch 25: accuracy improved from 0.67373 to 0.67722, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Epoch 25 - Top-5 Accuracy: 0.9375 - Precision: 0.6635\n",
      "1093/1093 [==============================] - 60s 55ms/step - loss: 1.0142 - accuracy: 0.6772 - auc: 0.9501 - val_loss: 0.9571 - val_accuracy: 0.6875 - val_auc: 0.9563 - lr: 0.0010\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092/1093 [============================>.] - ETA: 0s - loss: 0.9924 - accuracy: 0.6816 - auc: 0.9520\n",
      "Epoch 26: accuracy improved from 0.67722 to 0.68157, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Epoch 26 - Top-5 Accuracy: 0.9375 - Precision: 0.6354\n",
      "1093/1093 [==============================] - 61s 55ms/step - loss: 0.9925 - accuracy: 0.6816 - auc: 0.9520 - val_loss: 0.9230 - val_accuracy: 0.6562 - val_auc: 0.9604 - lr: 0.0010\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 0.9872 - accuracy: 0.6844 - auc: 0.9522\n",
      "Epoch 27: accuracy improved from 0.68157 to 0.68443, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Epoch 27 - Top-5 Accuracy: 0.9688 - Precision: 0.7005\n",
      "1093/1093 [==============================] - 60s 55ms/step - loss: 0.9872 - accuracy: 0.6844 - auc: 0.9522 - val_loss: 0.9996 - val_accuracy: 0.7188 - val_auc: 0.9545 - lr: 0.0010\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 0.9753 - accuracy: 0.6915 - auc: 0.9540\n",
      "Epoch 28: accuracy improved from 0.68443 to 0.69147, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Epoch 28 - Top-5 Accuracy: 0.9688 - Precision: 0.6771\n",
      "1093/1093 [==============================] - 60s 55ms/step - loss: 0.9753 - accuracy: 0.6915 - auc: 0.9540 - val_loss: 1.0254 - val_accuracy: 0.6562 - val_auc: 0.9430 - lr: 0.0010\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 0.9680 - accuracy: 0.6960 - auc: 0.9550\n",
      "Epoch 29: accuracy improved from 0.69147 to 0.69599, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Epoch 29 - Top-5 Accuracy: 1.0000 - Precision: 0.6323\n",
      "1093/1093 [==============================] - 60s 55ms/step - loss: 0.9680 - accuracy: 0.6960 - auc: 0.9550 - val_loss: 1.0191 - val_accuracy: 0.6562 - val_auc: 0.9531 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "   1/1093 [..............................] - ETA: 1:17 - loss: 1.2042 - accuracy: 0.6562 - auc: 0.9349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - ETA: 0s - loss: 0.9513 - accuracy: 0.6980 - auc: 0.9565\n",
      "Epoch 30: accuracy improved from 0.69599 to 0.69797, saving model to ./softplus.h5\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch 30 - Top-5 Accuracy: 0.9688 - Precision: 0.7437\n",
      "1093/1093 [==============================] - 53s 48ms/step - loss: 0.9513 - accuracy: 0.6980 - auc: 0.9565 - val_loss: 1.0635 - val_accuracy: 0.6875 - val_auc: 0.9467 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "final = original_model.fit(\n",
    "    image,\n",
    "    steps_per_epoch=len(image),\n",
    "    epochs=30,\n",
    "    validation_data=(validate_data_1, validate_labels),\n",
    "    validation_steps=len(validate_data_1),\n",
    "    verbose=1,\n",
    "    callbacks=callbs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267c3af-9966-4a29-8117-8e65505ffa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b35d69a-77d7-4c8c-af93-8f3766c98097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Calculate top-5 accuracy\n",
    "    top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "    top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "\n",
    "    return top_5_accuracy, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c36fcf-e48f-46da-9b7f-4347dbbb947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.1532 - accuracy: 0.6562 - auc: 0.9387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 13:27:38.332267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 314ms/step - loss: 1.1532 - accuracy: 0.6562 - auc: 0.9387\n",
      "Test loss: 1.1532411575317383\n",
      "Test accuracy: 0.65625\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      " Top-5 Accuracy: 1.0000\n",
      "Precision: 0.8203\n"
     ]
    }
   ],
   "source": [
    "prediction = original_model.evaluate(X_test , Y_test,verbose=1)\n",
    "print('Test loss:', prediction[0])\n",
    "print('Test accuracy:', prediction[1])\n",
    "\n",
    "predictions = original_model.predict(X_test)\n",
    "top_5_accuracy, precision = calculate_metrics(np.argmax(Y_test, axis=1), predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f' Top-5 Accuracy: {top_5_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4aef46e-dae6-47cf-93e5-33ad3ce2885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = final.history\n",
    "h.keys()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.title(\"Loss vs Acc\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
