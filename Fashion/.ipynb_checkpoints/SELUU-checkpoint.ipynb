{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82494a0c-f7d4-4359-b5f9-3ed922e28f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.13.0\n",
      "GPU is  Available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"tensorflow version : {tf.__version__}\")\n",
    "# print(f\"keras version : {tensorflow.keras.__version__}\")\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is \" , \"Available\" if gpu else \"NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf95bbb1-3ae6-43ec-a7f0-6605be48ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import precision_score\n",
    "from tensorflow.keras import regularizers\n",
    "import shutil\n",
    "import glob\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Dense\n",
    "from keras.layers import Conv2D , GlobalAveragePooling2D , MaxPooling2D,Dropout , Flatten , Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.framework.func_graph import flatten\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import  InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import  preprocess_input\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38b75f63-fbf8-4a65-862f-a927dd2ee984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Dress', 6000), ('Sneaker', 6000), ('Coat', 6000), ('Sandal', 6000), ('Angle boot', 6000), ('T-shirt', 6000), ('Bag', 6000), ('Shirt', 6000), ('Pullover', 6000), ('Trouser', 6000)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"data\"\n",
    "number_of_images = {}\n",
    "\n",
    "for dir in os.listdir(root_dir):\n",
    "    # Ignore .DS_Store files\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Check if the item is a directory before listing its contents\n",
    "    if os.path.isdir(os.path.join(root_dir, dir)):\n",
    "        number_of_images[dir] = len(os.listdir(os.path.join(root_dir, dir)))\n",
    "\n",
    "print(number_of_images.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "917d50d1-0d00-470f-892b-0a2e323f8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldercreation (path , split) :\n",
    "    if not os.path.exists('./'+path):\n",
    "      os.mkdir('./'+path)\n",
    "\n",
    "      for dir in os.listdir(root_dir):\n",
    "        if dir == '.DS_Store':\n",
    "           continue\n",
    "            \n",
    "        os.makedirs('./'+path+\"/\"+dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)) , size = (math.floor(split * number_of_images[dir])-5) , replace=False):\n",
    "          Original = os.path.join(root_dir,dir,img)\n",
    "          Destination =os.path.join('./'+path , dir)\n",
    "          shutil.copy(Original,Destination)\n",
    "          # os.remove(Original)\n",
    "\n",
    "    else:\n",
    "      print(\"The folder exsist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d030332f-42c5-45fe-a9df-0b2a9b5017d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder exsist\n",
      "The folder exsist\n",
      "The folder exsist\n"
     ]
    }
   ],
   "source": [
    "foldercreation(\"train_data\",0.7)\n",
    "foldercreation(\"validation_data\",0.15)\n",
    "foldercreation(\"test_data\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1199e693-d2a0-4659-8991-706065051243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = ImageDataGenerator (\n",
    "                                     \n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      preprocessing_function= preprocess_input,\n",
    "                                )\n",
    "\n",
    "image=image_data.flow_from_directory(directory=\"train_data\" ,\n",
    "                                       target_size=(28,28),\n",
    "                                       batch_size=32,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "964c9fed-0872-4410-9a39-496bbb9903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2 (path):\n",
    "  image_data = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "  image = image_data.flow_from_directory(directory = path,\n",
    "                                         target_size=(28,28),\n",
    "                                         batch_size = 32,\n",
    "                                         shuffle=True,\n",
    "                                         class_mode = \"categorical\")\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd18e7b0-ba7d-4a5f-980a-7dc3073d0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_test =\"test_data\"\n",
    "test_data = preprocessing2(path_test)\n",
    "X_test , Y_test = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "304013d9-6d94-42dc-8e5f-6e07aa03aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_validate=\"validation_data\"\n",
    "validate_data = preprocessing2(path_validate)\n",
    "validate_data_1 , validate_labels = validate_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b9579cd-cd00-4c61-bf70-6e9c4fc0a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layer_1 (inputs,filters):\n",
    "\n",
    "\n",
    "  convo_2x2 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='selu')(inputs)\n",
    "  convo_3x3 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='selu')(inputs)\n",
    "  pool_conv = Conv2D(filters=filters[2], kernel_size=(3,3), padding='same', activation='selu')(inputs)\n",
    "\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([convo_2x2, convo_3x3, pool_conv])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_2 (inputs,filters):\n",
    "\n",
    "\n",
    "\n",
    "  convo_3x3 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='selu')(inputs)\n",
    "  pool_3x3 =MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(convo_3x3)\n",
    "\n",
    "  convo_5x5 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='selu')(inputs)\n",
    "  pool_5x5 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(convo_5x5)\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([pool_3x3, pool_5x5])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_3 (inputs,filters):\n",
    "    \n",
    "  convo_1x1 = Conv2D(filters=filters[0], kernel_size=(3,3), padding='same', activation='selu')(inputs)\n",
    "  pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "  outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "# def model_layer_5 (inputs,filters):\n",
    "    \n",
    "#   convo_1x1 = Conv2D(filters=filters[0], kernel_size=(5,5), padding='same', activation='relu')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "# def model_layer_6 (inputs):\n",
    "    \n",
    "#   pool_3x3 = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, pool_3x3])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7fb6b60-b00f-4849-a8f0-cd2f02b411fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "# define input tensor\n",
    "\n",
    "input_tensor = Input(shape=(28, 28, 3))\n",
    "\n",
    "\n",
    "original_model = model_layer_3(input_tensor,[128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "\n",
    "\n",
    "original_model = model_layer_1(original_model,[32,64,128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2),padding='same')(original_model)\n",
    "original_model = model_layer_2(original_model,[128,64])\n",
    "\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "original_model = model_layer_3(original_model,[128])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6cc7fa87-ee6b-492e-8b39-c938722e9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_model = Flatten()(original_model)\n",
    "original_model = Dense(512, activation='selu' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dense(256, activation='selu' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dropout(0.5)(original_model)\n",
    "\n",
    "output_tensor = Dense(10, activation='softmax' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "\n",
    "original_model = Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "040bd7f7-895c-4e21-9194-c500ec6c59a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 28, 28, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooli  (None, 28, 28, 3)            0         ['input_5[0][0]']             \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 28, 28, 128)          3584      ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 28, 28, 131)          0         ['max_pooling2d_22[0][0]',    \n",
      " e)                                                                  'conv2d_28[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooli  (None, 14, 14, 131)          0         ['concatenate_10[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 14, 14, 32)           16800     ['max_pooling2d_23[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 14, 14, 64)           75520     ['max_pooling2d_23[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 14, 14, 128)          151040    ['max_pooling2d_23[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenat  (None, 14, 14, 224)          0         ['conv2d_29[0][0]',           \n",
      " e)                                                                  'conv2d_30[0][0]',           \n",
      "                                                                     'conv2d_31[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooli  (None, 7, 7, 224)            0         ['concatenate_11[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 7, 7, 128)            114816    ['max_pooling2d_24[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 7, 7, 64)             129088    ['max_pooling2d_24[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_25 (MaxPooli  (None, 7, 7, 128)            0         ['conv2d_32[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " max_pooling2d_26 (MaxPooli  (None, 7, 7, 64)             0         ['conv2d_33[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 7, 7, 192)            0         ['max_pooling2d_25[0][0]',    \n",
      " e)                                                                  'max_pooling2d_26[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_27 (MaxPooli  (None, 4, 4, 192)            0         ['concatenate_12[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " max_pooling2d_28 (MaxPooli  (None, 4, 4, 192)            0         ['max_pooling2d_27[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 4, 4, 128)            221312    ['max_pooling2d_27[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenat  (None, 4, 4, 320)            0         ['max_pooling2d_28[0][0]',    \n",
      " e)                                                                  'conv2d_34[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 5120)                 0         ['concatenate_13[0][0]']      \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 512)                  2621952   ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 256)                  131328    ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 256)                  0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 10)                   2570      ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3468010 (13.23 MB)\n",
      "Trainable params: 3468010 (13.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "909495f2-933b-4cfa-826b-bbb1890983f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "original_model.compile(optimizer= opt ,\n",
    "              loss= keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy' , 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ab155de-6383-4f99-adce-e2d575457f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor=\"accuracy\",\n",
    "                          min_delta=0.01 , patience=3,\n",
    "                          verbose=1,\n",
    "                          mode=\"auto\")\n",
    "modelcheckpoint = ModelCheckpoint(monitor=\"accuracy\",\n",
    "                                  filepath = \"./selu.h5\",\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  mode =\"auto\"\n",
    "                                  )\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-3)\n",
    "\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        predictions = self.model.predict(x_val)\n",
    "        \n",
    "        # Calculate top-5 accuracy\n",
    "        top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "        true_labels = np.argmax(y_val, axis=1)\n",
    "        top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Top-5 Accuracy: {top_5_accuracy:.4f} - Precision: {precision:.4f}')\n",
    "\n",
    "\n",
    "metrics_callback = MetricsCallback(validation_data=(validate_data_1, validate_labels))\n",
    "\n",
    "callbs = [earlystop,modelcheckpoint,lr_scheduler,metrics_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fdd759-3059-4565-912b-aa46961a283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 00:53:15.835801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310/1311 [============================>.] - ETA: 0s - loss: 1.0468 - accuracy: 0.7086 - auc: 0.9634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 00:53:45.947425: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.70863, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "Epoch 1 - Top-5 Accuracy: 1.0000 - Precision: 0.9307\n",
      "1311/1311 [==============================] - 31s 23ms/step - loss: 1.0464 - accuracy: 0.7086 - auc: 0.9635 - val_loss: 0.4671 - val_accuracy: 0.9062 - val_auc: 0.9925 - lr: 0.0010\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2023-12-18 00:53:46.792879: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.7958 - auc: 0.9807\n",
      "Epoch 2: accuracy improved from 0.70863 to 0.79583, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 2 - Top-5 Accuracy: 1.0000 - Precision: 0.7943\n",
      "1311/1311 [==============================] - 30s 23ms/step - loss: 0.6355 - accuracy: 0.7958 - auc: 0.9807 - val_loss: 0.3974 - val_accuracy: 0.8750 - val_auc: 0.9934 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "   4/1311 [..............................] - ETA: 31s - loss: 0.5675 - accuracy: 0.8672 - auc: 0.9814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310/1311 [============================>.] - ETA: 0s - loss: 0.5659 - accuracy: 0.8159 - auc: 0.9833\n",
      "Epoch 3: accuracy improved from 0.79583 to 0.81597, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 3 - Top-5 Accuracy: 1.0000 - Precision: 0.9307\n",
      "1311/1311 [==============================] - 31s 24ms/step - loss: 0.5657 - accuracy: 0.8160 - auc: 0.9833 - val_loss: 0.4875 - val_accuracy: 0.9062 - val_auc: 0.9782 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "   4/1311 [..............................] - ETA: 29s - loss: 0.6597 - accuracy: 0.7500 - auc: 0.9790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5403 - accuracy: 0.8247 - auc: 0.9837\n",
      "Epoch 4: accuracy improved from 0.81597 to 0.82472, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 4 - Top-5 Accuracy: 1.0000 - Precision: 0.9062\n",
      "1311/1311 [==============================] - 31s 24ms/step - loss: 0.5403 - accuracy: 0.8247 - auc: 0.9837 - val_loss: 0.5151 - val_accuracy: 0.8750 - val_auc: 0.9746 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "   4/1311 [..............................] - ETA: 31s - loss: 0.5386 - accuracy: 0.8047 - auc: 0.9863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310/1311 [============================>.] - ETA: 0s - loss: 0.5062 - accuracy: 0.8349 - auc: 0.9853\n",
      "Epoch 5: accuracy improved from 0.82472 to 0.83483, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 5 - Top-5 Accuracy: 1.0000 - Precision: 0.9234\n",
      "1311/1311 [==============================] - 31s 24ms/step - loss: 0.5061 - accuracy: 0.8348 - auc: 0.9853 - val_loss: 0.3255 - val_accuracy: 0.8750 - val_auc: 0.9959 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "   4/1311 [..............................] - ETA: 29s - loss: 0.4570 - accuracy: 0.8438 - auc: 0.9902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.8347 - auc: 0.9845\n",
      "Epoch 6: accuracy did not improve from 0.83483\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Epoch 6 - Top-5 Accuracy: 1.0000 - Precision: 0.8516\n",
      "1311/1311 [==============================] - 32s 24ms/step - loss: 0.5109 - accuracy: 0.8347 - auc: 0.9845 - val_loss: 0.6193 - val_accuracy: 0.8438 - val_auc: 0.9744 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8379 - auc: 0.9849\n",
      "Epoch 7: accuracy improved from 0.83483 to 0.83788, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Epoch 7 - Top-5 Accuracy: 1.0000 - Precision: 0.9375\n",
      "1311/1311 [==============================] - 31s 24ms/step - loss: 0.5047 - accuracy: 0.8379 - auc: 0.9849 - val_loss: 0.2595 - val_accuracy: 0.9062 - val_auc: 0.9971 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "   4/1311 [..............................] - ETA: 31s - loss: 0.5240 - accuracy: 0.8672 - auc: 0.9848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 835/1311 [==================>...........] - ETA: 11s - loss: 0.4748 - accuracy: 0.8450 - auc: 0.9861"
     ]
    }
   ],
   "source": [
    "final = original_model.fit(\n",
    "    image,\n",
    "    steps_per_epoch=len(image),\n",
    "    epochs=30,\n",
    "    validation_data=(validate_data_1, validate_labels),\n",
    "    validation_steps=len(validate_data_1),\n",
    "    verbose=1,\n",
    "    callbacks=callbs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267c3af-9966-4a29-8117-8e65505ffa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35d69a-77d7-4c8c-af93-8f3766c98097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Calculate top-5 accuracy\n",
    "    top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "    top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "\n",
    "    return top_5_accuracy, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c36fcf-e48f-46da-9b7f-4347dbbb947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = original_model.evaluate(X_test , Y_test,verbose=1)\n",
    "print('Test loss:', prediction[0])\n",
    "print('Test accuracy:', prediction[1])\n",
    "\n",
    "predictions = original_model.predict(X_test)\n",
    "top_5_accuracy, precision = calculate_metrics(np.argmax(Y_test, axis=1), predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f' Top-5 Accuracy: {top_5_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aef46e-dae6-47cf-93e5-33ad3ce2885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = final.history\n",
    "h.keys()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.title(\"Loss vs Acc\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
