{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82494a0c-f7d4-4359-b5f9-3ed922e28f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.13.0\n",
      "GPU is  Available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"tensorflow version : {tf.__version__}\")\n",
    "# print(f\"keras version : {tensorflow.keras.__version__}\")\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is \" , \"Available\" if gpu else \"NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf95bbb1-3ae6-43ec-a7f0-6605be48ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import precision_score\n",
    "from tensorflow.keras import regularizers\n",
    "import shutil\n",
    "import glob\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, AveragePooling2D, Flatten, Dense\n",
    "from keras.layers import Conv2D , GlobalAveragePooling2D , MaxPooling2D,Dropout , Flatten , Dense, BatchNormalization, GlobalAvgPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.framework.func_graph import flatten\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model , load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import  InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import  preprocess_input\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b75f63-fbf8-4a65-862f-a927dd2ee984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('Dress', 6000), ('Sneaker', 6000), ('Coat', 6000), ('Sandal', 6000), ('Angle boot', 6000), ('T-shirt', 6000), ('Bag', 6000), ('Shirt', 6000), ('Pullover', 6000), ('Trouser', 6000)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"data\"\n",
    "number_of_images = {}\n",
    "\n",
    "for dir in os.listdir(root_dir):\n",
    "    # Ignore .DS_Store files\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Check if the item is a directory before listing its contents\n",
    "    if os.path.isdir(os.path.join(root_dir, dir)):\n",
    "        number_of_images[dir] = len(os.listdir(os.path.join(root_dir, dir)))\n",
    "\n",
    "print(number_of_images.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917d50d1-0d00-470f-892b-0a2e323f8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldercreation (path , split) :\n",
    "    if not os.path.exists('./'+path):\n",
    "      os.mkdir('./'+path)\n",
    "\n",
    "      for dir in os.listdir(root_dir):\n",
    "        if dir == '.DS_Store':\n",
    "           continue\n",
    "            \n",
    "        os.makedirs('./'+path+\"/\"+dir)\n",
    "\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)) , size = (math.floor(split * number_of_images[dir])-5) , replace=False):\n",
    "          Original = os.path.join(root_dir,dir,img)\n",
    "          Destination =os.path.join('./'+path , dir)\n",
    "          shutil.copy(Original,Destination)\n",
    "          # os.remove(Original)\n",
    "\n",
    "    else:\n",
    "      print(\"The folder exsist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d030332f-42c5-45fe-a9df-0b2a9b5017d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder exsist\n",
      "The folder exsist\n",
      "The folder exsist\n"
     ]
    }
   ],
   "source": [
    "foldercreation(\"train_data\",0.7)\n",
    "foldercreation(\"validation_data\",0.15)\n",
    "foldercreation(\"test_data\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1199e693-d2a0-4659-8991-706065051243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = ImageDataGenerator (\n",
    "                                     \n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      preprocessing_function= preprocess_input,\n",
    "                                )\n",
    "\n",
    "image=image_data.flow_from_directory(directory=\"train_data\" ,\n",
    "                                       target_size=(28,28),\n",
    "                                       batch_size=32,\n",
    "                                       shuffle=True,\n",
    "                                       class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964c9fed-0872-4410-9a39-496bbb9903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing2 (path):\n",
    "  image_data = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "  image = image_data.flow_from_directory(directory = path,\n",
    "                                         target_size=(28,28),\n",
    "                                         batch_size = 32,\n",
    "                                         shuffle=True,\n",
    "                                         class_mode = \"categorical\")\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd18e7b0-ba7d-4a5f-980a-7dc3073d0c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_test =\"test_data\"\n",
    "test_data = preprocessing2(path_test)\n",
    "X_test , Y_test = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304013d9-6d94-42dc-8e5f-6e07aa03aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8950 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "path_validate=\"validation_data\"\n",
    "validate_data = preprocessing2(path_validate)\n",
    "validate_data_1 , validate_labels = validate_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9579cd-cd00-4c61-bf70-6e9c4fc0a1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Usage example with TensorFlow Addons\n",
    "gelu = tfa.activations.gelu\n",
    "\n",
    "def model_layer_1 (inputs,filters):\n",
    "\n",
    "\n",
    "  convo_2x2 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='gelu')(inputs)\n",
    "  convo_3x3 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='gelu')(inputs)\n",
    "  pool_conv = Conv2D(filters=filters[2], kernel_size=(3,3), padding='same', activation='gelu')(inputs)\n",
    "\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([convo_2x2, convo_3x3, pool_conv])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_2 (inputs,filters):\n",
    "\n",
    "\n",
    "\n",
    "  convo_3x3 = Conv2D(filters=filters[0], kernel_size=(2,2), padding='same', activation='gelu')(inputs)\n",
    "  pool_3x3 =MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(convo_3x3)\n",
    "\n",
    "  convo_5x5 = Conv2D(filters=filters[1], kernel_size=(3,3), padding='same', activation='gelu')(inputs)\n",
    "  pool_5x5 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(convo_5x5)\n",
    "\n",
    "  outputs = Concatenate(axis=-1)([pool_3x3, pool_5x5])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def model_layer_3 (inputs,filters):\n",
    "    \n",
    "  convo_1x1 = Conv2D(filters=filters[0], kernel_size=(3,3), padding='same', activation='gelu')(inputs)\n",
    "  pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "  outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "# def model_layer_5 (inputs,filters):\n",
    "    \n",
    "#   convo_1x1 = Conv2D(filters=filters[0], kernel_size=(5,5), padding='same', activation='relu')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, convo_1x1])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "# def model_layer_6 (inputs):\n",
    "    \n",
    "#   pool_3x3 = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(inputs)\n",
    "#   pool_1x1 = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same')(inputs)\n",
    "#   outputs = Concatenate(axis=-1)([pool_1x1, pool_3x3])\n",
    "\n",
    "#   return outputs\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fb6b60-b00f-4849-a8f0-cd2f02b411fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 00:41:33.037961: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-12-18 00:41:33.037997: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-18 00:41:33.038010: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-18 00:41:33.038060: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-18 00:41:33.038084: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "\n",
    "# define input tensor\n",
    "\n",
    "input_tensor = Input(shape=(28, 28, 3))\n",
    "\n",
    "\n",
    "original_model = model_layer_3(input_tensor,[128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "\n",
    "\n",
    "original_model = model_layer_1(original_model,[32,64,128])\n",
    "original_model = MaxPooling2D(pool_size=(2,2),padding='same')(original_model)\n",
    "original_model = model_layer_2(original_model,[128,64])\n",
    "\n",
    "original_model = MaxPooling2D(pool_size=(2,2) ,padding='same')(original_model)\n",
    "original_model = model_layer_3(original_model,[128])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc7fa87-ee6b-492e-8b39-c938722e9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_model = Flatten()(original_model)\n",
    "original_model = Dense(512, activation='gelu' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dense(256, activation='gelu' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "original_model = Dropout(0.5)(original_model)\n",
    "\n",
    "output_tensor = Dense(10, activation='softmax' ,kernel_regularizer=regularizers.l2(0.001))(original_model)\n",
    "\n",
    "original_model = Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040bd7f7-895c-4e21-9194-c500ec6c59a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)           896       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)           0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)           4128      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)           18496     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 128)          36992     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 14, 14, 224)          0         ['conv2d_1[0][0]',            \n",
      "                                                                     'conv2d_2[0][0]',            \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 224)            0         ['concatenate[0][0]']         \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 128)            114816    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)             129088    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 128)            0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 7, 7, 192)            0         ['max_pooling2d_2[0][0]',     \n",
      " )                                                                   'max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 64)             110656    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 2, 2, 64)             0         ['conv2d_6[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 256)                  0         ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  32896     ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 10)                   1290      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 449258 (1.71 MB)\n",
      "Trainable params: 449258 (1.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909495f2-933b-4cfa-826b-bbb1890983f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "original_model.compile(optimizer= opt ,\n",
    "              loss= keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy' , 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab155de-6383-4f99-adce-e2d575457f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor=\"accuracy\",\n",
    "                          min_delta=0.01 , patience=3,\n",
    "                          verbose=1,\n",
    "                          mode=\"auto\")\n",
    "modelcheckpoint = ModelCheckpoint(monitor=\"accuracy\",\n",
    "                                  filepath = \"./gelu.h5\",\n",
    "                                  verbose=1,\n",
    "                                  save_best_only=True,\n",
    "                                  mode =\"auto\"\n",
    "                                  )\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-3)\n",
    "\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data[0], self.validation_data[1]\n",
    "        predictions = self.model.predict(x_val)\n",
    "        \n",
    "        # Calculate top-5 accuracy\n",
    "        top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "        true_labels = np.argmax(y_val, axis=1)\n",
    "        top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1} - Top-5 Accuracy: {top_5_accuracy:.4f} - Precision: {precision:.4f}')\n",
    "\n",
    "\n",
    "metrics_callback = MetricsCallback(validation_data=(validate_data_1, validate_labels))\n",
    "\n",
    "callbs = [earlystop,modelcheckpoint,lr_scheduler,metrics_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fdd759-3059-4565-912b-aa46961a283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 00:41:33.935715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309/1311 [============================>.] - ETA: 0s - loss: 0.7428 - accuracy: 0.7715 - auc: 0.9775"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 00:42:11.933572: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: accuracy improved from -inf to 0.77137, saving model to ./relu.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2023-12-18 00:42:13.538331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n",
      "Epoch 1 - Top-5 Accuracy: 1.0000 - Precision: 0.9229\n",
      "1311/1311 [==============================] - 40s 29ms/step - loss: 0.7427 - accuracy: 0.7714 - auc: 0.9775 - val_loss: 0.4183 - val_accuracy: 0.8750 - val_auc: 0.9947 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.8506 - auc: 0.9892\n",
      "Epoch 2: accuracy improved from 0.77137 to 0.85063, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 2 - Top-5 Accuracy: 1.0000 - Precision: 0.9359\n",
      "1311/1311 [==============================] - 34s 26ms/step - loss: 0.4780 - accuracy: 0.8506 - auc: 0.9892 - val_loss: 0.3736 - val_accuracy: 0.9062 - val_auc: 0.9937 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "   3/1311 [..............................] - ETA: 36s - loss: 0.5521 - accuracy: 0.8021 - auc: 0.9869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.8706 - auc: 0.9916\n",
      "Epoch 3: accuracy improved from 0.85063 to 0.87063, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 3 - Top-5 Accuracy: 1.0000 - Precision: 0.9281\n",
      "1311/1311 [==============================] - 32s 24ms/step - loss: 0.4058 - accuracy: 0.8706 - auc: 0.9916 - val_loss: 0.2867 - val_accuracy: 0.9062 - val_auc: 0.9970 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "   3/1311 [..............................] - ETA: 35s - loss: 0.4095 - accuracy: 0.8750 - auc: 0.9925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.8801 - auc: 0.9927\n",
      "Epoch 4: accuracy improved from 0.87063 to 0.88007, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Epoch 4 - Top-5 Accuracy: 1.0000 - Precision: 0.9359\n",
      "1311/1311 [==============================] - 31s 24ms/step - loss: 0.3703 - accuracy: 0.8801 - auc: 0.9927 - val_loss: 0.2534 - val_accuracy: 0.9062 - val_auc: 0.9980 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "   4/1311 [..............................] - ETA: 30s - loss: 0.4105 - accuracy: 0.8828 - auc: 0.9890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1311/1311 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8866 - auc: 0.9931\n",
      "Epoch 5: accuracy improved from 0.88007 to 0.88663, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Epoch 5 - Top-5 Accuracy: 1.0000 - Precision: 0.9359\n",
      "1311/1311 [==============================] - 31s 24ms/step - loss: 0.3494 - accuracy: 0.8866 - auc: 0.9931 - val_loss: 0.2268 - val_accuracy: 0.9062 - val_auc: 0.9980 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "   4/1311 [..............................] - ETA: 30s - loss: 0.3910 - accuracy: 0.8750 - auc: 0.9904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310/1311 [============================>.] - ETA: 0s - loss: 0.3295 - accuracy: 0.8913 - auc: 0.9939\n",
      "Epoch 6: accuracy improved from 0.88663 to 0.89128, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Epoch 6 - Top-5 Accuracy: 1.0000 - Precision: 0.9750\n",
      "1311/1311 [==============================] - 31s 24ms/step - loss: 0.3296 - accuracy: 0.8913 - auc: 0.9939 - val_loss: 0.1899 - val_accuracy: 0.9688 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "   4/1311 [..............................] - ETA: 30s - loss: 0.4280 - accuracy: 0.8594 - auc: 0.9890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310/1311 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.8979 - auc: 0.9943\n",
      "Epoch 7: accuracy improved from 0.89128 to 0.89793, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 7 - Top-5 Accuracy: 1.0000 - Precision: 0.9750\n",
      "1311/1311 [==============================] - 31s 24ms/step - loss: 0.3140 - accuracy: 0.8979 - auc: 0.9943 - val_loss: 0.1607 - val_accuracy: 0.9688 - val_auc: 0.9990 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "   4/1311 [..............................] - ETA: 31s - loss: 0.4526 - accuracy: 0.8359 - auc: 0.9874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309/1311 [============================>.] - ETA: 0s - loss: 0.3051 - accuracy: 0.9003 - auc: 0.9945\n",
      "Epoch 8: accuracy improved from 0.89793 to 0.90038, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Epoch 8 - Top-5 Accuracy: 1.0000 - Precision: 0.9750\n",
      "1311/1311 [==============================] - 30s 23ms/step - loss: 0.3049 - accuracy: 0.9004 - auc: 0.9945 - val_loss: 0.1691 - val_accuracy: 0.9688 - val_auc: 0.9989 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "   4/1311 [..............................] - ETA: 32s - loss: 0.3189 - accuracy: 0.8906 - auc: 0.9950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309/1311 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.9036 - auc: 0.9946\n",
      "Epoch 9: accuracy improved from 0.90038 to 0.90358, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Epoch 9 - Top-5 Accuracy: 1.0000 - Precision: 0.9750\n",
      "1311/1311 [==============================] - 30s 23ms/step - loss: 0.2981 - accuracy: 0.9036 - auc: 0.9946 - val_loss: 0.1408 - val_accuracy: 0.9688 - val_auc: 0.9994 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "   4/1311 [..............................] - ETA: 29s - loss: 0.3326 - accuracy: 0.8750 - auc: 0.9943"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310/1311 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.9071 - auc: 0.9950\n",
      "Epoch 10: accuracy improved from 0.90358 to 0.90706, saving model to ./relu.h5\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Epoch 10 - Top-5 Accuracy: 1.0000 - Precision: 0.9516\n",
      "1311/1311 [==============================] - 30s 23ms/step - loss: 0.2869 - accuracy: 0.9071 - auc: 0.9950 - val_loss: 0.2025 - val_accuracy: 0.9375 - val_auc: 0.9984 - lr: 0.0010\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/likhit/venv-metal/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "final = original_model.fit(\n",
    "    image,\n",
    "    steps_per_epoch=len(image),\n",
    "    epochs=30,\n",
    "    validation_data=(validate_data_1, validate_labels),\n",
    "    validation_steps=len(validate_data_1),\n",
    "    verbose=1,\n",
    "    callbacks=callbs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267c3af-9966-4a29-8117-8e65505ffa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angle boot': 0,\n",
       " 'Bag': 1,\n",
       " 'Coat': 2,\n",
       " 'Dress': 3,\n",
       " 'Pullover': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'T-shirt': 8,\n",
       " 'Trouser': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b35d69a-77d7-4c8c-af93-8f3766c98097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Calculate top-5 accuracy\n",
    "    top_5 = np.argsort(predictions, axis=1)[:, -5:]\n",
    "    top_5_accuracy = np.mean([1 if true_label in pred_classes else 0 for true_label, pred_classes in zip(true_labels, top_5)])\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='weighted')\n",
    "\n",
    "    return top_5_accuracy, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c36fcf-e48f-46da-9b7f-4347dbbb947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 00:46:52.587940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3625 - accuracy: 0.9062 - auc: 0.9932\n",
      "Test loss: 0.3624523878097534\n",
      "Test accuracy: 0.90625\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      " Top-5 Accuracy: 1.0000\n",
      "Precision: 0.9359\n"
     ]
    }
   ],
   "source": [
    "prediction = original_model.evaluate(X_test , Y_test,verbose=1)\n",
    "print('Test loss:', prediction[0])\n",
    "print('Test accuracy:', prediction[1])\n",
    "\n",
    "predictions = original_model.predict(X_test)\n",
    "top_5_accuracy, precision = calculate_metrics(np.argmax(Y_test, axis=1), predictions)\n",
    "\n",
    "# Print metrics\n",
    "print(f' Top-5 Accuracy: {top_5_accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4aef46e-dae6-47cf-93e5-33ad3ce2885e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = final.history\n",
    "h.keys()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(h['loss'])\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.title(\"Loss vs Acc\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
